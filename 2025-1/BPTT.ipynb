{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Retropropagación**\n",
    "\n",
    "El algoritmo de **retropropagación** (backpropagation) es la pieza central del aprendizaje de redes neuronales feed-forward. Permite ajustar los pesos de la red para que la salida se aproxime a un valor deseado, minimizando una función de costo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.hidden_layer = nn.Linear(num_inputs, num_hidden)\n",
    "        self.output_layer = nn.Linear(num_hidden, num_outputs)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.sigmoid(self.hidden_layer(x))\n",
    "        output = self.sigmoid(self.output_layer(hidden))\n",
    "        return output\n",
    "\n",
    "# Cambiando el nombre de la instancia para evitar confusión\n",
    "modelo = NeuralNetwork(num_inputs=2, num_hidden=2, num_outputs=2)\n",
    "\n",
    "# Optimizador y función de pérdida\n",
    "optimizer = optim.SGD(modelo.parameters(), lr=0.5)\n",
    "criterion = nn.MSELoss()  # Instancia correctamente MSELoss\n",
    "\n",
    "# Datos de entrenamiento\n",
    "inputs = torch.tensor([[0.05, 0.1]], dtype=torch.float32)\n",
    "targets = torch.tensor([[0.01, 0.99]], dtype=torch.float32)\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for i in range(10000):\n",
    "    modelo.zero_grad()           # Resetea los gradientes\n",
    "    outputs = modelo(inputs)     # Pase hacia adelante\n",
    "    loss = criterion(outputs, targets)  # Calcula la pérdida\n",
    "    loss.backward()             # Pase hacia atrás\n",
    "    optimizer.step()            # Actualiza los parámetros\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print(f'Epoca {i}, Loss: {loss.item()}')\n",
    "\n",
    "# Código opcionalmente añadido para validación/pruebas\n",
    "# Supongamos que tenemos datos de validación:\n",
    "validation_inputs = torch.tensor([[0.1, 0.2]], dtype=torch.float32)\n",
    "validation_targets = torch.tensor([[0.05, 0.95]], dtype=torch.float32)\n",
    "\n",
    "# Evaluar el modelo en modo de evaluación\n",
    "modelo.eval()\n",
    "with torch.no_grad():  # Desactiva el cálculo de gradientes\n",
    "    validation_outputs = modelo(validation_inputs)\n",
    "    validation_loss = criterion(validation_outputs, validation_targets)\n",
    "    print(f'Pérdida de validación: {validation_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo:\n",
    "\n",
    "```python\n",
    "modelo = NeuralNetwork(num_inputs=2, num_hidden=2, num_outputs=2)\n",
    "optimizer = optim.SGD(modelo.parameters(), lr=0.5)\n",
    "criterion = nn.MSELoss()\n",
    "```\n",
    "\n",
    "- Definimos una red muy sencilla (2->2->2), útil para ilustrar paso a paso el flujo de gradientes.\n",
    "- Usamos **SGD** (descenso por gradiente estocástico) con tasa de aprendizaje 0.5, y **MSELoss** como función de costo, ideal para regresión o salidas continuas en rango (0,1) tras aplicar sigmoide.\n",
    "\n",
    "Escribimos la arquitectura y el mapeo al código:\n",
    "\n",
    "```python\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super().__init__()\n",
    "        self.hidden_layer = nn.Linear(num_inputs, num_hidden)\n",
    "        self.output_layer = nn.Linear(num_hidden, num_outputs)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "```\n",
    "\n",
    "- **`nn.Linear`** encapsula los pesos $\\mathbf{W}$ y sesgos $\\mathbf{b}$ de cada capa.\n",
    "- **`self.sigmoid`** es la función de activación $\\sigma(z)=1/(1+e^{-z})$, que introduce no-linealidad y \"aplana\" valores fuera del rango $[0,1]$.\n",
    "\n",
    "En la práctica, esta red calcula:\n",
    "\n",
    "1. $\\mathbf{z}^{(1)} = W^{(1)}x + b^{(1)}$  \n",
    "2. $\\mathbf{a}^{(1)} = \\sigma(\\mathbf{z}^{(1)})$  \n",
    "3. $\\mathbf{z}^{(2)} = W^{(2)}a^{(1)} + b^{(2)}$  \n",
    "4. $\\mathbf{a}^{(2)} = \\sigma(\\mathbf{z}^{(2)})$  \n",
    "\n",
    "donde $x$ es el tensor `inputs`.\n",
    "\n",
    "Dentro del bucle de entrenamiento:\n",
    "\n",
    "```python\n",
    "outputs = modelo(inputs)     # Pase hacia adelante\n",
    "loss = criterion(outputs, targets)\n",
    "```\n",
    "\n",
    "- `modelo(inputs)` invoca `forward(x)` que aplica dos veces `self.sigmoid(self.hidden_layer(x))` y luego `self.sigmoid(self.output_layer(hidden))`.\n",
    "- `criterion(outputs, targets)` calcula  \n",
    "  $$\n",
    "    E = \\tfrac12\\sum_j\\bigl(a_j^{(2)} - y_j\\bigr)^2,\n",
    "  $$  \n",
    "  donde `targets` es el tensor objetivo $\\mathbf{y}$.\n",
    "\n",
    "Este valor escalar `loss` cuantifica cuánto difiere la predicción de la realidad deseada.\n",
    "\n",
    "\n",
    "Calculamos los gradientes y la retropropagación\n",
    "\n",
    "```python\n",
    "loss.backward()             # Pase hacia atrás\n",
    "```\n",
    "\n",
    "Al invocar `.backward()`, PyTorch recorre el grafo computacional construido durante el forward, aplicando la **regla de la cadena** para cada parámetro:\n",
    "\n",
    "1. **Salida → capa de salida**  \n",
    "   $$\n",
    "   \\delta^{(2)} = (\\mathbf{a}^{(2)} - \\mathbf{y}) \\;\\odot\\; \\sigma'(\\mathbf{z}^{(2)})\n",
    "   $$\n",
    "2. **Capa de salida → capa oculta**  \n",
    "   $$\n",
    "   \\delta^{(1)} = \\bigl(W^{(2)\\,T}\\,\\delta^{(2)}\\bigr)\\odot\\sigma'(\\mathbf{z}^{(1)})\n",
    "   $$\n",
    "3. **Gradientes**  \n",
    "   $\\nabla_{W^{(l)}}E = \\delta^{(l)}\\,(a^{(l-1)})^T,\\quad \\nabla_{b^{(l)}}E = \\delta^{(l)}$.\n",
    "\n",
    "Internamente, PyTorch acumula estos gradientes en cada tensor de parámetros (`.grad`), listos para que el optimizador los use.\n",
    "\n",
    "\n",
    "Realizamos la optimización de parámetros:\n",
    "\n",
    "```python\n",
    "optimizer.step()            # Actualiza los parámetros\n",
    "```\n",
    "\n",
    "- **`optimizer.step()`** toma cada parámetro $ \\theta $ y hace  \n",
    "  $$\n",
    "    \\theta \\leftarrow \\theta - \\eta \\,\\frac{\\partial E}{\\partial \\theta}\n",
    "  $$  \n",
    "  donde $\\eta=0.5$.  \n",
    "- Antes de esto, en cada iteración, se limpia el gradiente:\n",
    "  ```python\n",
    "  modelo.zero_grad()\n",
    "  ```\n",
    "  para evitar acumular gradientes de pasos anteriores.\n",
    "\n",
    "Este ciclo (`zero_grad`, `forward`, `loss.backward`, `step`) es la esencia del aprendizaje para la retropropagación.\n",
    "\n",
    "Mostramos el rol del bucle de entrenamiento y épocas:\n",
    "\n",
    "```python\n",
    "for i in range(10000):\n",
    "    …\n",
    "    if i % 1000 == 0:\n",
    "        print(f'Epoca {i}, Loss: {loss.item()}')\n",
    "```\n",
    "\n",
    "- Iteramos 10 000 veces sobre el mismo dato (toy example).  \n",
    "- En redes reales, reemplazaríamos `inputs` y `targets` por **mini-lotes** de datos, mejorando la generalización y la estabilidad del entrenamiento.\n",
    "- Imprimir la pérdida cada 1 000 iteraciones permite monitorear la **convergencia**: observaremos cómo $E$ decrece gradualmente.\n",
    "\n",
    "Tras el entrenamiento, pasamos a evaluar:\n",
    "\n",
    "```python\n",
    "modelo.eval()             # Desactiva Dropout/BatchNorm (aquí no hay)\n",
    "with torch.no_grad():    # Desactiva cálculo de gradientes\n",
    "    validation_outputs = modelo(validation_inputs)\n",
    "    validation_loss = criterion(validation_outputs, validation_targets)\n",
    "    print(f'Pérdida de validación: {validation_loss.item()}')\n",
    "```\n",
    "\n",
    "- **`modelo.eval()`** pone la red en modo evaluación. Aunque la red no usa **dropout** ni **BatchNorm**, es buena práctica activarlo siempre.\n",
    "- **`torch.no_grad()`** reduce memoria y acelera la evaluación al omitir el grafo de cálculo de gradientes.\n",
    "- Comparamos la **pérdida de validación** con la de entrenamiento para detectar **sobreajuste**. Si la validación fuese muy mayor, significaría que la red memorizó el dato de entrenamiento sin generalizar.\n",
    "\n",
    "**Importancia de los hiperparámetros y posibles extensiones**\n",
    "\n",
    "1. **Tasa de aprendizaje ($\\eta$)**  \n",
    "   - Un valor demasiado alto ($\\eta>1$) puede hacer que el entrenamiento **diverja**.  \n",
    "   - Uno muy bajo ($\\eta<0.01$) ralentiza la convergencia.\n",
    "\n",
    "2. **Número de iteraciones/épocas**  \n",
    "   - Ajustar según la complejidad del problema y tamaño de datos reales.\n",
    "   - Podríamos usar un **scheduler** (`optim.lr_scheduler`) para disminuir $\\eta$ durante el entrenamiento.\n",
    "\n",
    "3. **Función de activación**  \n",
    "   - Sustituir sigmoide por **ReLU** o **tanh** mejora la **propagación de gradientes** en redes profundas.\n",
    "\n",
    "4. **Regularización**  \n",
    "   - Añadir **Dropout** o **weight decay** (L2) reduce sobreajuste en conjuntos de datos más grandes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ejercicios**\n",
    "\n",
    "**Ejercicio 1:** Crea una red neuronal simple (por ejemplo, una red con una capa oculta) desde cero en Python. Implementa manualmente el algoritmo de retropropagación para actualizar los pesos de la red.  Utiliza esta red para entrenar un modelo que pueda clasificar puntos en dos clases basadas en su posición en un plano 2D. Genera datos sintéticos que sean linealmente separables.\n",
    "\n",
    "**Ejercicio 2:**  Modifica la red del ejercicio 1 para probar diferentes funciones de activación (ReLU, sigmoidal, tanh) en la capa oculta.  Compara el rendimiento del entrenamiento con cada función de activación. Observa cómo cambia la rapidez de convergencia y si alguna configuración es particularmente propensa a problemas como el desvanecimiento o la explosión de gradientes.\n",
    "\n",
    "**Ejercicio 3:** Añade L2 (ridge) o L1 (lasso) regularización a la red neuronal que creaste en el ejercicio 1. Entrena la red en un conjunto de datos más complejo que introduzca algo de ruido y observa si la regularización ayuda a mejorar la generalización del modelo.\n",
    "\n",
    "**Ejercicio 4:** Implementa la retropropagación utilizando diferentes tamaños de batch: desde el descenso de gradiente estocástico (un ejemplo a la vez) hasta el descenso de gradiente por lotes (usando todo el conjunto de datos a la vez). Analiza cómo cambian la estabilidad y la velocidad de convergencia del entrenamiento con los diferentes tamaños de batch. Considera incluir una visualización de la disminución de la pérdida a lo largo de las iteraciones para cada configuración de tamaño de batch.\n",
    "\n",
    "**Ejercicio 5:**  Utiliza la red neuronal del ejercicio 1 y experimenta con diferentes tasas de aprendizaje y números de épocas de entrenamiento. Implementa una búsqueda de cuadrícula o aleatoria para encontrar la combinación óptima de tasa de aprendizaje y número de épocas. Evalúa el rendimiento del modelo en un conjunto de validación para determinar la mejor configuración de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Backpropagation through time (BPTT)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intentaremos explicar BPTT, un algoritmo de retropropagación utilizado para entrenar redes neuronales recurrentes (RNN). Mostraremos la derivación matemática así como el código de implementación. Para el código, usaremos PyTorch para poder comparar los gradientes calculados automáticamente por PyTorch con los calculados manualmente. \n",
    "\n",
    "En primer lugar, definamos matemáticamente lo que hace una RNN en cada paso de tiempo $t$.\n",
    "\n",
    "Sea $x_t \\in \\mathbb{R}^{d_x}$ un vector de entrada en el paso de tiempo $t$. Una RNN de tamaño $d_h$ calcula su estado oculto $h_t$ como:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  r_t &= U x_t + V h_{t-1} \\\\\n",
    "  h_t &= f \\left( r_t \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "donde $U \\in \\mathbb{R}^{d_h \\times d_x}$ y $V \\in \\mathbb{R}^{d_h \\times d_h}$ son parámetros, y $f$ es una función de activación. Nota que no incluimos el término de sesgo aquí por simplicidad.\n",
    "\n",
    "Un vector de salida $y_t \\in \\mathbb{R}^{d_o}$ entonces puede ser calculado como:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  s_t &= W h_t \\\\\n",
    "  y_t &= g \\left( s_t \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "donde $W \\in \\mathbb{R}^{d_o \\times d_h}$ es un parámetro y $g$ es una función de salida no lineal, que depende de la tarea (por ejemplo, softmax para clasificación). Aquí también no incluimos el término de sesgo por simplicidad. Nota que $U$, $V$, y $W$ se comparten a lo largo de los pasos de tiempo, es decir, no hay matrices separadas para cada paso de tiempo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Proceso**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea $L = \\mathcal{L}(y_t)$ la pérdida de nuestra RNN. Uno podría intentar derivar los gradientes de $U$, $V$, $W$ de manera ingenua. Por ejemplo, para calcular el gradiente sobre $W$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_{ij}} = \\sum_k \\frac{\\partial L}{\\partial (s_t)_k} \\frac{\\partial (s_t)_k}{\\partial W_{ij}}\n",
    "$$\n",
    "\n",
    "Dado que\n",
    "\n",
    "$$\n",
    "\\frac{\\partial (s_t)_k}{\\partial W_{ij}} =\n",
    "\\begin{cases}\n",
    "0 & k \\neq i \\\\\n",
    "(h_t)_j & \\text{de lo contrario}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "tenemos\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_{ij}} = \\frac{\\partial L}{\\partial (s_t)_i} (h_t)_j\n",
    "$$\n",
    "\n",
    "O, en notación matricial\n",
    "\n",
    "$$\n",
    "\\overline{W} = \\overline{s}_t h_t^{\\top}\n",
    "$$\n",
    "\n",
    "donde la notación de barra denota el gradiente de $ L $ con respecto a él, es decir, $\\overline{A}_{ij} = \\frac{\\partial L}{\\partial A_{ij}}$ y $\\overline{a}_i = \\frac{\\partial L}{\\partial a_i}$.\n",
    "\n",
    "Sin embargo, esto es **incorrecto**. Dado que $W$ se comparte a lo largo de los pasos de tiempo, contribuye a $s_t$ para *todos* los pasos de tiempo  $t$. Por lo tanto, al calcular el gradiente, necesitamos sumar los gradientes de todos los pasos de tiempo. En otras palabras, lo que necesitamos es:\n",
    "\n",
    "$$\n",
    "\\overline{W} = \\sum_t \\overline{s}_t h_t^{\\top}\n",
    "$$\n",
    "\n",
    "Los gradientes sobre $U$ y $V$ se pueden calcular de manera similar, es decir\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\overline{U} &= \\sum_t \\overline{r}_t x_t^{\\top} \\\\\n",
    "  \\overline{V} &= \\sum_t \\overline{r}_t h_{t-1}^{\\top}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Ahora, los últimos gradientes. Gradiente sobre $r_t$ es\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\frac{\\partial L}{\\partial (r_t)_i}\n",
    "  &= \\sum_j \\frac{\\partial L}{\\partial (h_t)_j} \\frac{\\partial (h_t)_j}{\\partial (r_t)_i} \\\\\n",
    "  &= \\frac{\\partial L}{\\partial (h_t)_i} f' (r_t)_i\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "O, en notación vectorial\n",
    "\n",
    "$$\n",
    "\\overline{r}_t = \\overline{h}_t * f' (r_t)\n",
    "$$\n",
    "\n",
    "De manera similar, el gradiente sobre $s_t$ se puede mostrar como $\\overline{s}_t = \\overline{y}_t * g' (s_t)$.\n",
    "\n",
    "Por último, necesitamos calcular $\\overline{h}_t$. Note que $h_t$ contribuye a $s_t$, y si $t$ no es el último paso de tiempo, entonces también contribuye a $r_{t+1}$. Por lo tanto, si $T$ denota el último paso de tiempo, entonces\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\frac{\\partial L}{\\partial (h_T)_i}\n",
    "  &= \\sum_j \\frac{\\partial L}{\\partial (s_T)_j} \\frac{\\partial (s_T)_j}{\\partial (h_T)_i} \\\\\n",
    "  &= \\sum_j \\frac{\\partial L}{\\partial (s_T)_j} W_{ji}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "y para $t < T$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\frac{\\partial L}{\\partial (h_t)_i}\n",
    "  &= \\sum_j \\frac{\\partial L}{\\partial (s_t)_j} \\frac{\\partial (s_t)_j}{\\partial (h_t)_i}\n",
    "  + \\sum_k \\frac{\\partial L}{\\partial (r_{t+1})_k} \\frac{\\partial (r_{t+1})_k}{\\partial (h_t)_i} \\\\\n",
    "  &= \\sum_j \\frac{\\partial L}{\\partial (s_t)_j} W_{ji}\n",
    "  + \\sum_k \\frac{\\partial L}{\\partial (r_{t+1})_k} V_{ki}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "En notación matricial (y combinando los dos)\n",
    "\n",
    "$$\n",
    "\\overline{h}_t = W^{\\top} \\overline{s}_t +\n",
    "\\begin{cases}\n",
    "0 & t = T \\\\\n",
    "V^{\\top} \\overline{r}_{t+1} & \\text{de lo contrario}\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así, los gradientes completos son\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\overline{U} &= \\sum_t \\overline{r}_t x_t^{\\top} \\\\\n",
    "  \\overline{V} &= \\sum_t \\overline{r}_t h_{t-1}^{\\top} \\\\\n",
    "  \\overline{W} &= \\sum_t \\overline{s}_t h_t^{\\top} \\\\\n",
    "  \\overline{r}_t &= \\overline{h}_t * f' \\left( r_t \\right) \\\\\n",
    "  \\overline{s}_t &= \\overline{y}_t * g' \\left( s_t \\right) \\\\\n",
    "  \\overline{h}_t &= W^{\\top} \\overline{s}_t +\n",
    "    \\begin{cases}\n",
    "    0 & t = T \\\\\n",
    "    V^{\\top} \\overline{r}_{t+1} & \\text{de lo contrario}\n",
    "    \\end{cases}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ejemplo numérico de BPTT (dimensiones escalares, $T=2$)**\n",
    "\n",
    "**Definiciones**  \n",
    "- Dimensiones: $d_x=d_h=d_o=1$.  \n",
    "- Pasos de tiempo: $t=1,2$.  \n",
    "- Parámetros iniciales:\n",
    "  $$\n",
    "    U = 0.5,\\quad V = 0.1,\\quad W = 0.8.\n",
    "  $$\n",
    "- Activaciones: $f = \\tanh$, $g$ identidad.\n",
    "- Entradas:\n",
    "  $$\n",
    "    x_1 = 1.0,\\quad x_2 = 2.0.\n",
    "  $$\n",
    "- Objetivos:\n",
    "  $$\n",
    "    y^{\\ast}_1 = 0.0,\\quad y^{\\ast}_2 = 1.0.\n",
    "  $$\n",
    "- Pérdida total (suma de MSE en ambos $t$):\n",
    "  $$\n",
    "    L = \\tfrac12\\bigl(y_1 - y^{\\ast}_1\\bigr)^2 \\;+\\; \\tfrac12\\bigl(y_2 - y^{\\ast}_2\\bigr)^2.\n",
    "  $$\n",
    "- Notación:  \n",
    "  - $r_t = U x_t + V h_{t-1}$, con $h_0=0$.  \n",
    "  - $h_t = \\tanh(r_t)$.  \n",
    "  - $s_t = W h_t$.  \n",
    "  - $y_t = s_t$.  \n",
    "\n",
    "\n",
    "#### **1.  Paso forward**\n",
    "\n",
    "| Paso | Cálculo                             | Valor                                          |\n",
    "|:----:|:------------------------------------|:-----------------------------------------------|\n",
    "| $t=1$ | $r_1 = 0.5\\cdot1.0 + 0.1\\cdot0 = 0.5$ | $r_1 = 0.5$                                   |\n",
    "|        | $h_1 = \\tanh(0.5)\\approx0.4621$     | $h_1\\approx0.4621$                            |\n",
    "|        | $s_1 = 0.8\\cdot0.4621\\approx0.3697$ | $s_1\\approx0.3697$                            |\n",
    "|        | $y_1 = s_1\\approx0.3697$            | $y_1\\approx0.3697$                            |\n",
    "| $t=2$ | $r_2 = 0.5\\cdot2.0 + 0.1\\cdot0.4621$ | $r_2 = 1.0 + 0.04621 = 1.04621$               |\n",
    "|        | $h_2 = \\tanh(1.04621)\\approx0.7809$ | $h_2\\approx0.7809$                            |\n",
    "|        | $s_2 = 0.8\\cdot0.7809\\approx0.6247$ | $s_2\\approx0.6247$                            |\n",
    "|        | $y_2 = s_2\\approx0.6247$            | $y_2\\approx0.6247$                            |\n",
    "\n",
    "La pérdida:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L &= \\tfrac12(0.3697 - 0)^2 \\;+\\; \\tfrac12(0.6247 - 1)^2 \\\\\n",
    "  &= 0.5\\cdot0.1366 + 0.5\\cdot0.1408 \\approx 0.1387.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "#### **2. Paso backward: deltas y gradientes en cada $t$**\n",
    "\n",
    "Denotemos\n",
    "$\\overline{y}_t = \\frac{\\partial L}{\\partial y_t} = y_t - y^{\\ast}_t$.\n",
    "\n",
    "#### Paso $t=2$\n",
    "\n",
    "1. **Salida → gradiente de $s_2$**  \n",
    "   $$\n",
    "   \\overline{s}_2\n",
    "   = \\overline{y}_2 \\cdot g'(s_2)\n",
    "   = (0.6247 - 1.0)\\cdot1\n",
    "   = -0.3753.\n",
    "   $$\n",
    "\n",
    "2. **Gradiente de $W$** (acumular por todos los $t$)  \n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial W}\n",
    "   \\biggr\\rvert_{t=2}\n",
    "   = \\overline{s}_2 \\,h_2\n",
    "   = (-0.3753)\\cdot0.7809\n",
    "   \\approx -0.2929.\n",
    "   $$\n",
    "\n",
    "3. **Estado oculto → gradiente de $h_2$**  \n",
    "   $$\n",
    "   \\overline{h}_2\n",
    "   = W^{\\top}\\,\\overline{s}_2\n",
    "   = 0.8\\cdot(-0.3753)\n",
    "   = -0.3002\n",
    "   \\quad\\text{(no hay término $V^\\top \\overline r_3$ porque $t=2=T$).}\n",
    "   $$\n",
    "\n",
    "4. **Gradiente de $r_2$**  \n",
    "   $$\n",
    "   \\overline{r}_2\n",
    "   = \\overline{h}_2 \\;\\ast\\; f'(r_2)\n",
    "   = -0.3002 \\;\\ast\\; \\bigl(1 - \\tanh^2(1.0462)\\bigr)\n",
    "   = -0.3002\\cdot\\bigl(1 - 0.7809^2\\bigr)\n",
    "   = -0.3002\\cdot0.3904\n",
    "   \\approx -0.1172.\n",
    "   $$\n",
    "\n",
    "5. **Gradientes de $U$ y $V$** en $t=2$:  \n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial U}\\biggr\\rvert_{t=2}\n",
    "   = \\overline{r}_2\\,x_2\n",
    "   = (-0.1172)\\cdot2.0\n",
    "   = -0.2344,\n",
    "   \\qquad\n",
    "   \\frac{\\partial L}{\\partial V}\\biggr\\rvert_{t=2}\n",
    "   = \\overline{r}_2\\,h_1\n",
    "   = (-0.1172)\\cdot0.4621\n",
    "   \\approx -0.0542.\n",
    "   $$\n",
    "\n",
    "\n",
    "##### **Paso $t=1$**\n",
    "\n",
    "1. **Salida → gradiente de $s_1$**  \n",
    "   $$\n",
    "   \\overline{s}_1\n",
    "   = y_1 - y^{\\ast}_1\n",
    "   = 0.3697 - 0\n",
    "   = 0.3697.\n",
    "   $$\n",
    "\n",
    "2. **Gradiente de $W$** (acumular a lo ya obtenido)  \n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial W}\n",
    "   \\biggr\\rvert_{t=1}\n",
    "   = \\overline{s}_1\\,h_1\n",
    "   = 0.3697\\cdot0.4621\n",
    "   \\approx 0.1709.\n",
    "   $$\n",
    "   **Total**  \n",
    "   $\\displaystyle \\overline{W}\n",
    "   = -0.2929 + 0.1709\n",
    "   = -0.1220.$\n",
    "\n",
    "3. **Estado oculto → gradiente de $h_1$**  \n",
    "   Ahora $h_1$ influye en $s_1$ y en $r_2$, así que\n",
    "   $$\n",
    "   \\overline{h}_1\n",
    "   = W^{\\top}\\,\\overline{s}_1 \\;+\\; V^{\\top}\\,\\overline{r}_2\n",
    "   = 0.8\\cdot0.3697 \\;+\\; 0.1\\cdot(-0.1172)\n",
    "   = 0.2958 - 0.0117\n",
    "   = 0.2841.\n",
    "   $$\n",
    "\n",
    "4. **Gradiente de $r_1$**  \n",
    "   $$\n",
    "   \\overline{r}_1\n",
    "   = \\overline{h}_1 \\,\\ast\\, (1 - \\tanh^2(0.5))\n",
    "   = 0.2841\\cdot\\bigl(1 - 0.4621^2\\bigr)\n",
    "   = 0.2841\\cdot0.7861\n",
    "   \\approx 0.2233.\n",
    "   $$\n",
    "\n",
    "5. **Gradientes de $U$ y $V$** en $t=1$:  \n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial U}\\biggr\\rvert_{t=1}\n",
    "   = \\overline{r}_1\\,x_1\n",
    "   = 0.2233\\cdot1.0\n",
    "   = 0.2233,\n",
    "   \\qquad\n",
    "   \\frac{\\partial L}{\\partial V}\\biggr\\rvert_{t=1}\n",
    "   = \\overline{r}_1\\,h_0\n",
    "   = 0.2233\\cdot0\n",
    "   = 0.\n",
    "   $$\n",
    "   **Totales**  \n",
    "   $$\n",
    "   \\overline{U}\n",
    "   = -0.2344 + 0.2233\n",
    "   = -0.0111,\n",
    "   \\qquad\n",
    "   \\overline{V}\n",
    "   = -0.0542 + 0\n",
    "   = -0.0542.\n",
    "   $$\n",
    "\n",
    "\n",
    "#### 3. Resultados finales de los gradientes\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\begin{aligned}\n",
    "  \\overline{U} &\\approx -0.0111,  &\n",
    "  \\overline{V} &\\approx -0.0542,  &\n",
    "  \\overline{W} &\\approx -0.1220.\n",
    "\\end{aligned}\n",
    "}\n",
    "$$\n",
    "\n",
    "Y para cada paso:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  \\overline{r}_1 &\\approx  0.2233,  & \\overline{s}_1 &\\approx  0.3697,  & \\overline{h}_1 &\\approx  0.2841,\\\\\n",
    "  \\overline{r}_2 &\\approx -0.1172,  & \\overline{s}_2 &\\approx -0.3753,  & \\overline{h}_2 &\\approx -0.3002.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Este procedimiento es la base de BPTT: un forward para guardar $(r_t,h_t,s_t)$, y un backward que recorre $t=T$ hacia $1$ calculando $\\overline{h}_t,\\overline{r}_t,\\overline{s}_t$ y acumulando gradientes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Anotaciones adicionales**\n",
    "\n",
    "#### 1. Compartición de parámetros y acumulación de gradientes\n",
    "\n",
    "En una RNN los mismos parámetros $U,V,W$ se usan en **cada** paso de tiempo. Por tanto:\n",
    "\n",
    "- Cada aplicación de $W$ en el cálculo de $s_t = W\\,h_t$ aporta una \"porción\" de gradiente $\\overline{s}_t\\,h_t^\\top$.  \n",
    "- Para obtener el total, **sumamos** esas porciones sobre todos los $t$:\n",
    "  $$\n",
    "    \\overline{W} \\;=\\;\\sum_{t=1}^T \\overline{s}_t\\,h_t^\\top.\n",
    "  $$\n",
    "  \n",
    "Lo mismo sucede con $U$ y $V$. Esta suma refleja que, al optimizar, cada paso de tiempo \"empuja\" los pesos en direcciones potencialmente distintas, y la actualización final combina todas esas fuerzas.\n",
    "\n",
    "#### 2. Flujo de gradiente a través de la activación de salida ($\\overline{s}_t$)\n",
    "\n",
    "Para cada paso $t$, la salida intermedia $s_t = W\\,h_t$ genera la predicción $y_t = g(s_t)$. El gradiente\n",
    "\n",
    "$$\n",
    "\\overline{s}_t \\;=\\; \\frac{\\partial L}{\\partial y_t}\\;g'(s_t)\n",
    "$$\n",
    "\n",
    "toma en cuenta:\n",
    "\n",
    "1. **Error local**: $\\frac{\\partial L}{\\partial y_t}$ mide cuánto contribuye la salida en $t$ al costo total.  \n",
    "2. **Sensibilidad del no lineal**: $g'(s_t)$ ajusta ese error según la curvatura de la función $g$.  \n",
    "\n",
    "Ese producto nos dice \"cuánto deberíamos cambiar\" el vector $s_t$.\n",
    "\n",
    "\n",
    "#### 3. Transmisión del error hacia el estado oculto ($\\overline{h}_t$)\n",
    "\n",
    "El estado $h_t$ influye **directamente** en la pérdida a través de $s_t$, **y** (si no es el último paso) influye **indirectamente** al afectar el siguiente pre-activación $r_{t+1} = U x_{t+1} + V h_t$. Por eso\n",
    "\n",
    "$$\n",
    "\\overline{h}_t\n",
    "= W^\\top\\,\\overline{s}_t \n",
    "\\;+\\;\n",
    "\\begin{cases}\n",
    "0, & t=T,\\\\\n",
    "V^\\top\\,\\overline{r}_{t+1}, & t<T.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "- El primer término, $W^\\top\\,\\overline{s}_t$, \"retrae\" el error de la capa de salida.  \n",
    "- El segundo término, $V^\\top\\,\\overline{r}_{t+1}$, trae la contribución de **pasos futuros**. Esto es lo que convierte la retropropagación en \"por tiempo\" (temporal): el error circula hacia atrás por la conexión recurrente.\n",
    "\n",
    "\n",
    "#### 4. Paso al pre-activación ($\\overline{r}_t$)\n",
    "\n",
    "Una vez que sabemos $\\overline{h}_t$, lo transferimos a la variación en el pre-activación:\n",
    "\n",
    "$$\n",
    "\\overline{r}_t = \\overline{h}_t \\;\\ast\\; f'(r_t),\n",
    "$$\n",
    "\n",
    "donde $f'$ es la derivada de la no lineal interna (por ejemplo $\\tanh'$ o sigmoid’). Este factor **modula** cuánto del error de $h_t$ se atribuye a cada valor de $r_t$, según la pendiente local de $f$.  \n",
    "\n",
    "**Importante**: si $f'$ es muy pequeño (como en saturación), hace que $\\overline{r}_t$ se atenúe drásticamente—origen del problema de **vanishing gradients** en RNNs largas.\n",
    "\n",
    "\n",
    "#### 5. Contribución a $U$ y $V$\n",
    "\n",
    "Con $\\overline{r}_t$ definido, podemos asignar qué fracción de la variación total recae sobre $U$ y $V$ en ese paso:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial L}{\\partial U} &\\biggr\\rvert_{t}\n",
    "= \\overline{r}_t \\;x_t^\\top, \n",
    "&\n",
    "\\frac{\\partial L}{\\partial V} &\\biggr\\rvert_{t}\n",
    "= \\overline{r}_t \\;h_{t-1}^\\top.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Nuevamente, como estos parámetros se reutilizan, se suman sobre $t=1\\dots T$.\n",
    "\n",
    "\n",
    "#### 6. Interpretación como grafo acíclico \"desplegado\"\n",
    "\n",
    "Una forma de visualizarlo es **desplegando** la RNN en el tiempo, convirtiéndola en una red feed-forward muy profunda de $T$ \"capas\" donde:\n",
    "\n",
    "- Cada capa comparte los mismos pesos $U,V,W$.  \n",
    "- El gradiente fluye hacia atrás combinando rutas verticales (salida) y diagonales (recurrente).  \n",
    "\n",
    "Este grafo deja claro por qué hay que acumular a lo largo de las dos direcciones: espacial (capa a capa) y temporal (paso $t$ a $t-1$).\n",
    "\n",
    "\n",
    "#### 7. Validación con el ejemplo numérico\n",
    "\n",
    "En el ejemplo escalar con $T=2$:\n",
    "\n",
    "1. Se calculó $\\overline{s}_2$, $\\overline{h}_2$, $\\overline{r}_2$, y sus correspondientes contribuciones $\\overline{W}$, $\\overline{U}$, $\\overline{V}$.  \n",
    "2. Luego, en $t=1$, la \"segunda vía\" $V^\\top\\,\\overline{r}_2$ entró en $\\overline{h}_1$, mostrando cómo el error de $t=2$ retrocede a $t=1$.  \n",
    "3. Finalmente, al sumar las dos contribuciones de $\\overline{s}_1\\,h_1$ y $\\overline{s}_2\\,h_2$, surgió el total de $\\overline{W}$.\n",
    "\n",
    "Cada término numérico coincide exactamente con las fórmulas matriciales vistas arriba, confirmando la **coherencia** de la derivación.\n",
    "\n",
    "En general:\n",
    "\n",
    "- El **secreto** de BPTT está en rastrear dos flujos de error: el que va hacia la salida inmediata y el que se propaga hacia atrás en el tiempo.  \n",
    "- La compartición de pesos exige **sumar** las contribuciones de cada paso.  \n",
    "- La fórmula de $\\overline{h}_t$ es la clave: mezcla el gradiente \"local\" ($W^\\top\\overline{s}_t$) con el \"futuro\" ($V^\\top\\overline{r}_{t+1}$), y permite capturar dependencia temporal.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Implementacion en PyTorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación del cálculo hacia adelante (forward) es bastante directa. Comenzamos desde el paso de tiempo 1, y calculamos $r_t$, $h_t$, $s_t$ y $y_t$, dados los inputs $x_t$ y $h_{t-1}$, hasta el último paso de tiempo $T$. Comenzamos desde el paso de tiempo 1 porque en la relación de recurrencia, para calcular $r_t$ necesitamos $h_{t-1}$. Por lo tanto, el paso de tiempo anterior debe completarse primero.\n",
    "\n",
    "La implementación del cálculo hacia atrás es similar, pero en cambio comenzamos desde el último paso de tiempo $T$ hasta el primero. Esto se debe a que en la relación de recurrencia, necesitamos $\\overline{r}_{t+1}$ para calcular $\\overline{h}_t$. Así, el siguiente paso de tiempo debe completarse de antemano. Además, a medida que iteramos, necesitamos acumular los gradientes en $U$, $V$ y $W$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, vamos a crear una clase `RNNCell`. Esta clase es responsable de un solo paso de tiempo. \n",
    "\n",
    "Tiene los métodos forward y backward que realizan el cálculo hacia adelante y hacia atrás, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell:\n",
    "    \"\"\"Una celda RNN responsable de un solo paso de tiempo.\n",
    "\n",
    "    Args:\n",
    "        inp_sz (int): Tamaño de la entrada.\n",
    "        hid_sz (int): Tamaño del estado oculto.\n",
    "        out_sz (int): Tamaño de la salida.\n",
    "    \"\"\"\n",
    "    def __init__(self, inp_sz, hid_sz, out_sz):\n",
    "        self.inp_sz = inp_sz\n",
    "        self.hid_sz = hid_sz\n",
    "        self.out_sz = out_sz\n",
    "\n",
    "        # U, V, W son los parámetros, por lo que establecemos requires_grad=True\n",
    "        # para indicar a PyTorch que necesitamos calcular los gradientes\n",
    "        self.U = torch.empty(hid_sz, inp_sz, requires_grad=True)\n",
    "        self.V = torch.empty(hid_sz, hid_sz, requires_grad=True)\n",
    "        self.W = torch.empty(out_sz, hid_sz, requires_grad=True)\n",
    "\n",
    "        # Estos son los gradientes en U, V y W que calcularemos\n",
    "        # manualmente. También los compararemos con\n",
    "        # los gradientes calculados por PyTorch para ver si nuestro\n",
    "        # cálculo de gradientes es correcto.\n",
    "        self.U_grad = torch.zeros_like(self.U)\n",
    "        self.V_grad = torch.zeros_like(self.V)\n",
    "        self.W_grad = torch.zeros_like(self.W)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"Inicializar parámetros.\n",
    "\n",
    "        Los parámetros se inicializarán desde la distribución uniforme U(-0.1, 0.1).\n",
    "        \"\"\"\n",
    "        s = 0.1  # un valor mayor puede hacer que los gradientes exploten\n",
    "        torch.nn.init.uniform_(self.U, -s, s)\n",
    "        torch.nn.init.uniform_(self.V, -s, s)\n",
    "        torch.nn.init.uniform_(self.W, -s, s)\n",
    "    def zero_grad(self):\n",
    "        \"\"\"Se pone el gradiente a cero\"\"\"\n",
    "        self.U_grad.zero_()\n",
    "        self.V_grad.zero_()\n",
    "        self.W_grad.zero_()\n",
    "    \n",
    "    def forward(self, x, hp):\n",
    "        \"\"\"Realizar el cálculo hacia adelante.\n",
    "        \n",
    "        Args:\n",
    "            x (Tensor): Entrada en el paso de tiempo actual.\n",
    "            hp (Tensor): Estado oculto en el paso de tiempo anterior.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: Salida en el paso de tiempo actual.\n",
    "            Tensor: Estado oculto en el paso de tiempo actual.\n",
    "        \"\"\"\n",
    "        _, h, _, y = self._get_internals(x, hp)\n",
    "        return y, h\n",
    "\n",
    "    def backward(self, y_grad, rn_grad, x, hp):\n",
    "        \"\"\"Realizar el cálculo hacia atrás.\n",
    "        \n",
    "        Args:\n",
    "            y_grad (Tensor): Gradiente sobre la salida en el paso de tiempo actual.\n",
    "            rn_grad (Tensor): Gradiente sobre el vector r en el siguiente paso de tiempo.\n",
    "            x (Tensor): Entrada en el paso de tiempo actual que se pasó a `forward`.\n",
    "            hp (Tensor): Estado oculto en el paso de tiempo anterior que se pasó a `forward`.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: Gradiente sobre el vector r en el paso de tiempo actual.\n",
    "        \"\"\"\n",
    "        # Obtener los vectores internos r, h, y s del cálculo hacia adelante\n",
    "        r, h, s, _ = self._get_internals(x, hp)\n",
    "\n",
    "        s_grad = y_grad * torch.sigmoid(s) * (1-torch.sigmoid(s))\n",
    "        h_grad = self.W.t().matmul(s_grad) + self.V.t().matmul(rn_grad)\n",
    "        r_grad = h_grad * torch.sigmoid(r) * (1-torch.sigmoid(r))\n",
    "\n",
    "        # Los gradientes de los parámetros se acumulan\n",
    "        self.U_grad += r_grad.view(-1, 1).matmul(x.view(1, -1))\n",
    "        self.V_grad += r_grad.view(-1, 1).matmul(hp.view(1, -1))\n",
    "        self.W_grad += s_grad.view(-1, 1).matmul(h.view(1, -1))\n",
    "\n",
    "        return r_grad\n",
    "\n",
    "    def _get_internals(self, x, hp):\n",
    "        # Estos son los calculos forward reales\n",
    "        r = self.U.matmul(x) + self.V.matmul(hp)\n",
    "        h = torch.sigmoid(r)\n",
    "        s = self.W.matmul(h)\n",
    "        y = torch.sigmoid(s)\n",
    "        \n",
    "        return r, h, s, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, creemos una clase RNN. Esta clase acepta una `RNNCell` y es responsable de realizar la iteración sobre los pasos de tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, cell):\n",
    "        self.cell = cell\n",
    "    \n",
    "    def forward(self, xs, h0):\n",
    "        \"\"\"Realiza la computación hacia adelante para todos los pasos de tiempo.\n",
    "        \n",
    "        Args:\n",
    "            xs (Tensor): Tensor 2-D de entradas para cada paso de tiempo. La\n",
    "                primera dimensión corresponde al número de pasos de tiempo.\n",
    "            h0 (Tensor): Estado oculto inicial.\n",
    "            \n",
    "        Returns:\n",
    "            Tensor: Tensor 2-D de salidas para cada paso de tiempo. La primera\n",
    "                dimensión corresponde al número de pasos de tiempo.\n",
    "            Tensor: Tensor 2-D de estados ocultos para cada paso de tiempo más\n",
    "                `h0`. La primera dimensión corresponde al número de pasos de\n",
    "                tiempo.\n",
    "        \"\"\"\n",
    "        ys, hs = [], [h0]  # Inicializa listas vacías para almacenar las salidas y los estados ocultos\n",
    "        for x in xs:\n",
    "            y, h = self.cell.forward(x, hs[-1])  # Calcula la salida y el siguiente estado oculto\n",
    "            ys.append(y)  # Agrega la salida a la lista de salidas\n",
    "            hs.append(h)  # Agrega el estado oculto al final de la lista de estados ocultos\n",
    "        return torch.stack(ys), torch.stack(hs)  # Apila las salidas y los estados ocultos en tensores\n",
    "    \n",
    "    def backward(self, ys_grad, xs, hs):\n",
    "        \"\"\"Realiza la computación hacia atrás para todos los pasos de tiempo.\n",
    "        \n",
    "        Args:\n",
    "            ys_grad (Tensor): Tensor 2-D de los gradientes en las salidas\n",
    "                para cada paso de tiempo. La primera dimensión corresponde a\n",
    "                el número de pasos de tiempo.\n",
    "            xs (Tensor): Tensor 2-D de entradas para cada paso de tiempo que\n",
    "                fue pasado a `forward`.\n",
    "            hs (Tensor): Tensor 2-D de estados ocultos que es devuelto por\n",
    "                `forward`.\n",
    "        \"\"\"\n",
    "        # Para el último paso de tiempo, el gradiente en r es cero\n",
    "        rn_grad = torch.zeros(self.cell.hid_sz)  # Inicializa el gradiente de la celda recurrente como cero\n",
    "\n",
    "        for y_grad, x, hp in reversed(list(zip(ys_grad, xs, hs))):\n",
    "            rn_grad = cell.backward(y_grad, rn_grad, x, hp)  # Calcula el gradiente para cada paso de tiempo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, calculamos la función de pérdida. Aquí utilizamos una pérdida simple de suma de cuadrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(ys, ts):\n",
    "    return 0.5 * torch.sum((ys - ts)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, construimos la RNN. Tendrá un tamaño de entrada de 2, un tamaño oculto de 3 y un tamaño de salida de 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = RNNCell(2, 4, 5)\n",
    "rnn = RNN(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, creamos entradas y objetivos ficticios para la red recurrente. Estableceremos el número de pasos de tiempo en 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.rand(3, cell.inp_sz)\n",
    "hp = torch.rand(cell.hid_sz)\n",
    "ts = torch.rand(3, cell.out_sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, realizamos la computación del forward y calculamos la pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys, hs = rnn.forward(xs, hp)\n",
    "loss = compute_loss(ys, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Veamos los gradientes calculados por PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.cell.U.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.cell.V.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.cell.W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, ejecutemos nuestra computación backward y comparemos el resultado con el de PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto se obtiene de nuestra función de pérdida de suma de cuadrados\n",
    "ys_grad = ys - ts\n",
    "\n",
    "with torch.no_grad():  # necesario para que PyTorch no genere un erro\n",
    "    rnn.cell.zero_grad()\n",
    "    rnn.backward(ys_grad, xs, hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veamos si nuestros gradientes calculados manualmente son correctos, es decir, si son iguales a los de PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.cell.U_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.cell.V_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.cell.W_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Pregunta: comprueba si los resultados son iguales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicios**\n",
    "\n",
    "**Ejercicio 1**: Dado un simple RNN con una capa oculta y una función de activación sigmoide, realiza la derivación manual de los gradientes para los parámetros $U$, $V$ y $W$ utilizando BPTT. Asume que la RNN tiene una sola unidad oculta y procesa secuencias de tres tiempos.\n",
    "\n",
    "**Ejercicio 2**: Implementa una RNN simple en Python sin usar librerías de deep learning como TensorFlow o PyTorch. Tu RNN debe incluir métodos de forward y backward, y debe ser capaz de procesar secuencias de longitud variable.\n",
    "\n",
    "**Ejercicio 3**: Utiliza PyTorch para crear una RNN simple y compara los gradientes que calcula automáticamente con los que calculaste manualmente en el ejercicio 1 o implementaste en el ejercicio 2.\n",
    "\n",
    "**Ejercicio 4:** Modifica la RNN implementada en el ejercicio 2 para incluir secuencias de entrada de diferentes longitudes. Experimenta con inicializaciones de parámetros y observa cómo afectan a la magnitud de los gradientes durante el entrenamiento.\n",
    "\n",
    "**Ejercicio 5:** Implementa varias funciones de activación (ReLU, tanh, sigmoide) en tu RNN del ejercicio 2. Entrena tu modelo en un conjunto de datos de prueba simple (puede ser generado sintéticamente) y compara cómo la elección de la función de activación afecta el rendimiento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
