{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ajuste fino de Transformers con PyTorch y Hugging Face**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Configuración**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instalando librerías necesarias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todas las bibliotecas requeridas para este cuaderno están listadas a continuación.  \n",
    "# !pip install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 torch=2.1.0+cu118  \n",
    "# - Actualizar un paquete específico  \n",
    "# !pip install pmdarima -U  \n",
    "# - Actualizar un paquete a una versión concreta  \n",
    "# !pip install --upgrade pmdarima==2.0.2  \n",
    "# Nota: si tu entorno no admite `!pip install`, usa `!mamba install`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitarás ejecutar la siguiente celdas para instalarlas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers==4.42.1\n",
    "#!pip install datasets # 2.20.0\n",
    "#!pip install portalocker>=2.0.0\n",
    "#!pip install torch==2.3.1\n",
    "!pip install torchmetrics==1.4.0.post0\n",
    "#!pip install numpy==1.26.4\n",
    "#!pip install peft==0.11.1\n",
    "#!pip install evaluate==0.4.2\n",
    "#!pip install -q bitsandbytes==0.43.1\n",
    "#!pip install accelerate==0.31.0\n",
    "#!pip install torchvision==0.18.1\n",
    "\n",
    "\n",
    "#!pip install trl==0.9.4\n",
    "#!pip install protobuf==3.20.*\n",
    "#!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importación de librerías requeridas\n",
    "\n",
    "_Se recomienda que importes todas las librerías necesarias en un solo lugar (aquí):_\n",
    "\n",
    "* Nota: si obtienes un error al ejecutar la celda de abajo, intenta reiniciar el Kernel, ya que algunos paquetes necesitan un reinicio para que los cambios surtan efecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics import Accuracy\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoConfig,AutoModelForCausalLM,AutoModelForSequenceClassification,BertConfig,BertForMaskedLM,TrainingArguments, Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer,BertTokenizerFast,TextDataset,DataCollatorForLanguageModeling\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig,SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "#import pandas as pd\n",
    "\n",
    "\n",
    "# También puedes usar esta sección para suprimir las advertencias generadas por tu código:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ajuste fino(fine-tuning) supervisado con PyTorch**\n",
    "\n",
    "El ajuste fino de Transformers, específicamente de BERT (Bidirectional Encoder Representations from Transformers), se refiere al proceso de entrenar un modelo BERT previamente entrenado en una tarea específica. BERT es un modelo de lenguaje de solo codificador que ha sido preentrenado en un gran corpus de texto para aprender representaciones contextuales de las palabras.\n",
    "\n",
    "El ajuste fino de BERT implica tomar el modelo preentrenado y continuar entrenándolo con un conjunto de datos específico de la tarea, como análisis de sentimientos o respuesta a preguntas. Durante el ajuste fino, se actualizan y adaptan los parámetros del modelo BERT preentrenado a las particularidades de la tarea objetivo.\n",
    "\n",
    "Este proceso es importante porque te permite aprovechar el conocimiento y la comprensión del lenguaje que BERT ha capturado y aplicarlo a diferentes tareas. Al ajustar BERT, puedes beneficiarte de su comprensión contextual del lenguaje y transferir ese conocimiento a problemas específicos de dominio o de tareas concretas. El ajuste fino permite que BERT aprenda a partir de un conjunto de datos etiquetado más pequeño y generalice bien a ejemplos no vistos, lo que lo convierte en una herramienta potente para diversas tareas de procesamiento de lenguaje natural. \n",
    "\n",
    "Ayuda a cerrar la brecha entre el preentrenamiento en un gran corpus y los requisitos específicos de las aplicaciones, mejorando en última instancia el rendimiento y la efectividad de los modelos en diversos escenarios del mundo real.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Preparación del conjunto de datos**\n",
    "\n",
    "El conjunto de datos de reseñas de Yelp es un recurso ampliamente utilizado en investigación de procesamiento de lenguaje natural (NLP) y análisis de sentimientos. Consta de reseñas de usuarios y metadatos asociados de la plataforma Yelp, que es un sitio popular para evaluar y calificar negocios locales como restaurantes, hoteles y tiendas.\n",
    "\n",
    "El conjunto de datos incluye 6 990 280 reseñas escritas por usuarios de Yelp, que abarcan una amplia variedad de negocios y ubicaciones. Cada reseña generalmente contiene el texto de la opinión junto con la calificación en estrellas otorgada por el usuario (de 1 a 5).\n",
    "\n",
    "El objetivo en este cuaderno es ajustar finamente un modelo BERT preentrenado para predecir las calificaciones a partir de las reseñas.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos un registro de muestra del conjunto de datos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La etiqueta es la clave de la etiqueta de clase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][100][\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "también está el texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][100]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes seleccionar un subconjunto de datos para reducir el tiempo de entrenamiento:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].select([i for i in range(1000)])\n",
    "dataset[\"test\"] = dataset[\"test\"].select([i for i in range(200)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay dos campos de datos:  \n",
    "- label: la etiqueta de la reseña  \n",
    "- text: una cadena que contiene el cuerpo de la reseña del usuario  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenización de datos\n",
    "\n",
    "El siguiente paso es cargar un tokenizador de BERT para tokenizar, rellenar y truncar reseñas y así manejar secuencias de longitud variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia un tokenizador usando el modelo BERT base cased\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# Define una función para tokenizar ejemplos\n",
    "def tokenize_function(examples):\n",
    "    # Tokeniza el texto usando el tokenizador\n",
    "    # Aplica padding para asegurar que todas las secuencias tengan la misma longitud\n",
    "    # Aplica truncamiento para limitar la longitud máxima de la secuencia\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Aplica la función de tokenización al conjunto de datos por lotes\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las claves en cada elemento de `tokenized_datasets` son 'label', 'text', 'input_ids', 'token_type_ids' y 'attention_mask'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets['train'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aplicar la función de preprocesamiento en todo el conjunto de datos, vamos a usar el método `map`. Puedes acelerar la función `map` estableciendo `batched=True` para procesar varios elementos del conjunto de datos a la vez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que el modelo está construido sobre el framework PyTorch, es crucial preparar el conjunto de datos en un formato que PyTorch pueda procesar directamente. Sigue estos pasos para garantizar la compatibilidad:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina la columna 'text' porque el modelo no acepta texto sin procesar como entrada\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "\n",
    "# Renombra la columna 'label' a 'labels' porque el modelo espera un argumento llamado 'labels'\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Establece el formato del conjunto de datos para que devuelva tensores de PyTorch en lugar de listas\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es un conjunto de tensores con las claves: 'labels', 'input_ids', 'token_type_ids', 'attention_mask'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets['train'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, crea un DataLoader para los conjuntos de datos de entrenamiento y prueba para que puedas iterar sobre lotes de datos:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un DataLoader para entrenamiento\n",
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], shuffle=True, batch_size=2)\n",
    "\n",
    "# Crea un DataLoader para evaluación\n",
    "eval_dataloader = DataLoader(tokenized_datasets[\"test\"], batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Entrenar el modelo**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección, aprenderemos a crear el bucle de entrenamiento desde cero sin la ayuda de la clase `Trainer` de Hugging Face.\n",
    "\n",
    "Cargaremos un modelo de clasificación preentrenado con 5 clases:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia un modelo de clasificación de secuencias\n",
    "modelo = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizador y programación de la tasa de aprendizaje\n",
    "\n",
    "Vamos a crear un optimizador y un planificador de tasa de aprendizaje para ajustar el modelo. Puedes usar el optimizador AdamW de PyTorch:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define el optimizador\n",
    "optimizer = AdamW(modelo.parameters(), lr=5e-4)\n",
    "\n",
    "# Establece el número de épocas\n",
    "num_epochs = 10\n",
    "\n",
    "# Calcula el número total de pasos de entrenamiento\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "# Define el planificador de tasa de aprendizaje\n",
    "lr_scheduler = LambdaLR(\n",
    "    optimizer,\n",
    "    lr_lambda=lambda current_step: (1 - current_step / num_training_steps)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprueba si CUDA está disponible y, de ser así, establecer el dispositivo correspondiente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprueba si CUDA está disponible y, de ser así, establecer el dispositivo correspondiente\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Mueve el modelo al dispositivo apropiado\n",
    "modelo.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Bucle de entrenamiento**\n",
    " \n",
    "La función `train_model` entrena un modelo usando un conjunto de datos de entrenamiento proporcionado a través de un dataloader. Comienza configurando una barra de progreso para monitorear visualmente el entrenamiento. El modelo se pone en modo de entrenamiento, lo cual es necesario para que comportamientos como dropout funcionen correctamente. \n",
    "\n",
    "La función procesa los datos en lotes por cada época, lo que implica varios pasos para cada lote: transferir los datos al dispositivo correcto (por ejemplo, GPU), pasarlos por el modelo para obtener salidas y calcular la pérdida, actualizar los parámetros del modelo usando los gradientes calculados, ajustar la tasa de aprendizaje y limpiar los gradientes anteriores. \n",
    "\n",
    "Estos pasos se repiten para cada lote de datos, y la barra de progreso se actualiza para reflejar el avance. Una vez completadas todas las épocas, el modelo entrenado se guarda para usarse después.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(modelo, tr_dataloader):\n",
    "    # Crea una barra de progreso para seguir el progreso del entrenamiento\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "    # Pone el modelo en modo entrenamiento\n",
    "    modelo.train()\n",
    "    tr_losses = []\n",
    "\n",
    "    # Bucle de entrenamiento\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        # Itera sobre los lotes de datos de entrenamiento\n",
    "        for batch in tr_dataloader:\n",
    "            # Mueve el lote al dispositivo apropiado\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            # Paso forward por el modelo\n",
    "            outputs = modelo(**batch)\n",
    "            # Calcula la pérdida\n",
    "            loss = outputs.loss\n",
    "            # Paso backward (calcular gradientes)\n",
    "            loss.backward()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            # Actualiza los parámetros del modelo\n",
    "            optimizer.step()\n",
    "            # Actualiza el planificador de tasa de aprendizaje\n",
    "            lr_scheduler.step()\n",
    "            # Limpia los gradientes\n",
    "            optimizer.zero_grad()\n",
    "            # Actualiza la barra de progreso\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        tr_losses.append(total_loss / len(tr_dataloader))\n",
    "\n",
    "    # Grafica la pérdida\n",
    "    plt.plot(tr_losses)\n",
    "    plt.title(\"Pérdida de entrenamiento\")\n",
    "    plt.xlabel(\"Época\")\n",
    "    plt.ylabel(\"Pérdida\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Evaluación**\n",
    "\n",
    "La función `evaluate_model` funciona de forma similar a `train_model` pero se usa para evaluar el rendimiento del modelo en lugar de entrenarlo. \n",
    "\n",
    "Usa un dataloader para procesar datos en lotes, pone el modelo en modo evaluación para asegurar mediciones precisas, y desactiva el cálculo de gradientes ya que no se entrena. \n",
    "\n",
    "La función calcula predicciones para cada lote, actualiza una métrica de exactitud y, finalmente, imprime la precisión global tras procesar todos los lotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(modelo, evl_dataloader):\n",
    "    # Crea una instancia de la métrica accuracy para clasificación multiclase con 5 clases\n",
    "    metric = Accuracy(task=\"multiclass\", num_classes=5).to(device)\n",
    "\n",
    "    # Pone el modelo en modo evaluación\n",
    "    modelo.eval()\n",
    "\n",
    "    # Desactiva el cálculo de gradientes durante la evaluación\n",
    "    with torch.no_grad():\n",
    "        # Itera sobre los lotes de datos de evaluación\n",
    "        for batch in evl_dataloader:\n",
    "            # Mover el lote al dispositivo apropiado\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "            # Paso forward por el modelo\n",
    "            outputs = modelo(**batch)\n",
    "\n",
    "            # Obtiene las etiquetas predichas\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            # Acumula predicciones y etiquetas para la métrica\n",
    "            metric(predictions, batch[\"labels\"])\n",
    "\n",
    "    # Calcula la exactitud\n",
    "    accuracy = metric.compute()\n",
    "\n",
    "    # Imprimir la exactitud\n",
    "    print(\"Exactitud:\", accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedes ahora entrenar el modelo. Este proceso tomará bastante tiempo y se recomienda hacerlo solo si cuentas con los recursos necesarios. Descomenta el siguiente código para entrenar el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(modelp=model0,tr_dataloader=train_dataloader)\n",
    "# torch.save(modelo, 'modelo1.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![loss_gpt.png](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/HausLW2F_w30s1UK0zj7mQ/training-loss-BERT-Classification.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya estás listo para aprender a ajustar un modelo más complejo que pueda generar conversaciones entre un humano y un asistente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar el modelo guardado\n",
    "\n",
    "Si quieres omitir el entrenamiento y cargar el modelo que entrenaste por 10 épocas, descomenta la siguiente celda:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/wFhKpkBMSgjmZKRSyayvsQ/bert-classification-model.pt'\n",
    "modelo.load_state_dict(torch.load('bert-classification-model.pt',map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora puedes evaluar el modelo. Ten en cuenta que este proceso también tomará un tiempo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(modelo, eval_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya estás listo para aprender a ajustar un modelo más complejo que genere conversaciones entre un humano y un asistente usando `SFTtrainer`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio: Entrenamiento de un modelo conversacional usando SFTTrainer**\n",
    "\n",
    "Explora cómo el ajuste fino de un transformer decodificador usando un conjunto de datos específico afecta la calidad de las respuestas generadas en una tarea de preguntas y respuestas.\n",
    "\n",
    "1. **Paso 1**\n",
    "    - Cargar la partición de entrenamiento (`train split`) del dataset `\"timdettmers/openassistant-guanaco\"` desde Hugging Face.\n",
    "\n",
    "2. **Paso 2**\n",
    "    - Cargar el modelo causal preentrenado `\"facebook/opt-350m\"` junto con su tokenizador desde Hugging Face.\n",
    "\n",
    "3. **Paso 3**\n",
    "    - Definir plantillas de instrucción y respuesta basadas en el formato del dataset de entrenamiento.\n",
    "\n",
    "4. **Paso 4**\n",
    "    - Crear un collator que prepare los datos en la forma adecuada para el entrenamiento, usando `DataCollatorForCompletionOnlyLM`.\n",
    "\n",
    "5. **Paso 5**\n",
    "    - Instanciar un objeto `SFTTrainer` proporcionando el modelo, el dataset y el collator.\n",
    "\n",
    "6. **Paso 6**\n",
    "    - Generar una respuesta inicial del modelo preentrenado para una pregunta de ejemplo.\n",
    "\n",
    "7. **Paso 6A (Opcional)**\n",
    "    - Entrenar el modelo usando el `trainer.train()`.\n",
    "\n",
    "8. **Paso 6B**\n",
    "    - Si no dispones de recursos suficientes, cargar el modelo ajustado desde el enlace proporcionado.\n",
    "\n",
    "   ```python\n",
    "    # !wget 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/Assistant_model.pt'\n",
    "    # modelo.load_state_dict(torch.load('Assistant_model.pt',map_location=torch.device('cpu')))\n",
    "    ```\n",
    "9. **Paso 7**\n",
    "    - Evaluar cómo responde el modelo ajustado a la misma pregunta especializada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tu respuesta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "prev_pub_hash": "813811c42412546cc91d90735ea8e30caab5e8398335372a899df8c59fe00713"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
