{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94b7ca14-d87b-4b16-8ada-608833a5c2e2",
   "metadata": {},
   "source": [
    "### Normalización de palabras\n",
    "\n",
    "La normalización de palabras es el proceso de estandarizar palabras o tokens para que sigan un formato uniforme. Un ejemplo común de normalización es el **case folding**, que consiste en convertir todas las letras a minúsculas. Este enfoque permite que términos como \"Woodchuck\" y \"woodchuck\" se traten como idénticos, lo cual es particularmente útil para generalizar en tareas como la recuperación de información o el reconocimiento de voz.\n",
    "\n",
    "Sin embargo, en tareas como el análisis de sentimientos, la clasificación de textos, la extracción de información y la traducción automática, la distinción entre mayúsculas y minúsculas puede ser crucial. Por ejemplo, diferenciar entre \"US\" (Estados Unidos) y \"us\" (nosotros) puede ser más valioso que la simplificación que ofrecería el **case folding**. Por ello, en estos contextos, se suele optar por mantener las mayúsculas y minúsculas intactas. En algunos casos, se generan tanto versiones diferenciadas por el uso de mayúsculas como versiones uniformemente en minúsculas para modelos de lenguaje, dependiendo de la tarea específica.\n",
    "\n",
    "Los sistemas que emplean **BPE** u otros métodos de tokenización bottom-up pueden prescindir de una normalización adicional de las palabras. Sin embargo, en otros sistemas de **NLP**, puede ser beneficioso aplicar normalizaciones más avanzadas, como unificar diferentes formas de una palabra, por ejemplo, \"USA\" y \"US\" o \"uh-huh\" y \"uhhuh\". Esta estandarización, aunque implica la pérdida de cierta información ortográfica, puede ser valiosa. \n",
    "\n",
    "Por ejemplo, en la recuperación o extracción de información relacionada con \"US.\", podríamos querer identificar datos relevantes tanto si el documento menciona \"US\" como \"USA\".\n",
    "\n",
    "\n",
    "\n",
    "### Lematización\n",
    "\n",
    "Para otras situaciones de procesamiento de lenguaje natural, también queremos que dos formas morfológicamente diferentes de una palabra se comporten de manera similar. Por ejemplo, en la búsqueda web, alguien puede escribir la cadena \"woodchucks\", pero un sistema útil podría querer devolver páginas que mencionen \"woodchuck\" sin la \"s\". Esto es especialmente común en idiomas morfológicamente complejos como el polaco, donde, por ejemplo, la palabra \"Warsaw\" tiene diferentes terminaciones cuando es el sujeto (\"Warszawa\"), o después de una preposición como \"in Warsaw\" (\"w Warszawie\"), o \"to Warsaw\" (\"do Warszawy\"), y así sucesivamente. \n",
    "\n",
    "La **lematización** es la tarea de determinar que dos palabras tienen la misma raíz, a pesar de sus diferencias superficiales. Las palabras \"am\", \"are\" y \"is\" tienen el lema compartido \"be\"; las palabras \"dinner\" y \"dinners\" tienen el lema \"dinner\". Lematizar cada una de estas formas al mismo lema nos permitirá encontrar todas las menciones de palabras en polaco como \"Warsaw\". La forma lematizada de una oración como \"He is reading detective stories\" sería \"He be read detective story\".\n",
    "\n",
    "Los métodos más sofisticados para la lematización implican un análisis morfológico completo de la palabra. La morfología es el estudio de la forma en que las palabras se construyen a partir de unidades más pequeñas que llevan significado, llamadas **morfemas**. Se pueden distinguir dos grandes clases de morfemas: **stems**, el morfema central de la palabra, que proporciona el significado principal y **affixes**—que añaden significados \"adicionales\" de varios tipos. \n",
    "\n",
    "Por ejemplo, la palabra \"fox\" consiste en un morfema (el morfema \"fox\") y la palabra \"cats\" consiste en dos: el morfema \"cat\" y el morfema \"-s\". Un **morphological parser** toma una palabra como \"cats\" y la analiza en los dos morfemas \"cat\" y \"s\".\n",
    "\n",
    "\n",
    "### Stemming: The Porter stemmer\n",
    "\n",
    "Los algoritmos de lematización pueden ser complejos. Por esta razón, a veces utilizamos un método más simple pero que consiste principalmente en cortar los afijos finales de las palabras. Esta versión  del análisis morfológico se llama **stemming**. Por ejemplo, el clásico **Porter stemmer**, cuando se aplica al siguiente párrafo:\n",
    "\n",
    "```plaintext\n",
    "This was not the map we found in Billy Bones’s chest, but\n",
    "an accurate copy, complete in all things-names and heights\n",
    "and soundings-with the single exception of the red crosses\n",
    "and the written notes.\n",
    "```\n",
    "\n",
    "produce la siguiente salida:\n",
    "\n",
    "```plaintext\n",
    "Thi wa not the map we found in Billi Bone s chest but an\n",
    "accur copi complet in all thing name and height and sound\n",
    "with the singl except of the red cross and the written note\n",
    "```\n",
    "\n",
    "El algoritmo se basa en reglas de reescritura que se ejecutan en serie, con la salida de cada paso alimentada como entrada al siguiente paso. \n",
    "\n",
    "Algunas reglas de muestra (más en [https://tartarus.org/martin/PorterStemmer/](https://tartarus.org/martin/PorterStemmer/)):\n",
    "\n",
    "| **Regla**        | **Ejemplo**                        |\n",
    "|------------------|------------------------------------|\n",
    "| **ATIONAL → ATE**| (relational → relate)              |\n",
    "| **SSES → SS**    | (grasses → grass)                  |\n",
    "\n",
    "Los **stemmers** simples pueden ser útiles en casos donde necesitamos colapsar diferentes variantes del mismo lema. Sin embargo, son menos comúnmente usados en sistemas modernos ya que cometen errores tanto de sobregeneralización (lematizando \"policy\" a \"police\") como de subgeneralización (no lematizando \"European\" a \"Europe\").\n",
    "\n",
    "---\n",
    "\n",
    "### Segmentación de oraciones\n",
    "\n",
    "La **segmentación de oraciones** es otro paso importante en el procesamiento de texto. Las señales más útiles para segmentar un texto en oraciones son la puntuación, como puntos, signos de interrogación y signos de exclamación. Los signos de interrogación y exclamación son marcadores relativamente inequívocos de los límites de las oraciones. Los puntos, por otro lado, son más ambiguos. El carácter punto \".\" es ambiguo entre un marcador de límite de oración y un marcador de abreviaciones como \"Mr.\" o \"Inc.\". Por esta razón, la tokenización de oraciones y la tokenización de palabras pueden abordarse conjuntamente.\n",
    "\n",
    "En general, los métodos de tokenización de oraciones funcionan primero decidiendo (basado en reglas o aprendizaje automático) si un punto es parte de la palabra o es un marcador de límite de oración. Un diccionario de abreviaturas puede ayudar a determinar si el punto es parte de una abreviatura de uso común; los diccionarios pueden ser construidos a mano o aprendidos por máquina, al igual que el divisor de oraciones final. \n",
    "\n",
    "En el **[Stanford CoreNLP toolkit](https://stanfordnlp.github.io/CoreNLP/)** , por ejemplo, la división de oraciones se basa en reglas, una consecuencia determinista de la tokenización; una oración termina cuando una puntuación final de oración (., !, o ?) no está ya agrupada con otros caracteres en un token (como para una abreviatura o número), opcionalmente seguida por comillas finales o corchetes adicionales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854804be",
   "metadata": {},
   "source": [
    "Normalización de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c338e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case Folding\n",
    "def normalize_case(text):\n",
    "    \"\"\"Convierte todo el texto a minúsculas para la normalización.\"\"\"\n",
    "    return text.lower()\n",
    "\n",
    "# Ejemplo de uso\n",
    "text = \"Woodchuck\"\n",
    "normalized_text = normalize_case(text)\n",
    "print(normalized_text)  # Salida: \"woodchuck\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6204d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def unify_terms(text):\n",
    "    \"\"\"Reemplaza diferentes variantes de un término por una versión estándar.\"\"\"\n",
    "    term_mapping = {\n",
    "        \"USA\": \"US\",\n",
    "        \"uh-huh\": \"uhhuh\"\n",
    "    }\n",
    "    words = text.split()\n",
    "    unified_words = [term_mapping.get(word, word) for word in words]\n",
    "    return ' '.join(unified_words)\n",
    "\n",
    "# Ejemplo de uso\n",
    "text = \"The USA has many dialects. Uh-huh, that's true.\"\n",
    "unified_text = unify_terms(text)\n",
    "print(unified_text)  # Salida: \"The US has many dialects. uhhuh, that's true.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427734cf",
   "metadata": {},
   "source": [
    "Lematización usando nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8054d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Descargar recursos necesarios\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, pos='v') for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# Ejemplo de uso\n",
    "text = \"He is reading detective stories\"\n",
    "lemmatized_text = lemmatize_text(text)\n",
    "print(lemmatized_text)  # Salida: \"He be read detective story\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c3c847",
   "metadata": {},
   "source": [
    "Stemming usando el Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6ae857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Descargar recursos necesarios\n",
    "nltk.download('punkt')\n",
    "\n",
    "def stem_text(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    words = nltk.word_tokenize(text)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "# Ejemplo de uso\n",
    "text = \"\"\"\n",
    "This was not the map we found in Billy Bones’s chest, but\n",
    "an accurate copy, complete in all things-names and heights\n",
    "and soundings-with the single exception of the red crosses\n",
    "and the written notes.\n",
    "\"\"\"\n",
    "stemmed_text = stem_text(text)\n",
    "print(stemmed_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88018131",
   "metadata": {},
   "source": [
    "Segmentación de oraciones usando nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cb00da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def sentence_tokenize(text):\n",
    "    return nltk.sent_tokenize(text)\n",
    "\n",
    "# Ejemplo de uso\n",
    "text = \"This is a sentence. This is another sentence! Is this the third one?\"\n",
    "sentences = sentence_tokenize(text)\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb29ebe",
   "metadata": {},
   "source": [
    "**Ejercicio 1: Normalización de palabras en español y Quechua**\n",
    "\n",
    "1. **Objetivo:** Implementar un programa en Python que convierta las palabras de un texto dado a minúsculas y unifique ciertas variantes de términos tanto en español como en quechua.\n",
    "   \n",
    "2. **Descripción:** \n",
    "   - Escribe una función que normalice el caso (convierta todo a minúsculas).\n",
    "   - Implementa una función que unifique palabras comunes con variantes ortográficas en español y quechua. Por ejemplo, \"Kusikuy\" (alegrarse) y \"Kusi\" (alegría) podrían normalizarse a \"kusikuy\".\n",
    "   - Procesa un texto que incluya palabras tanto en español como en quechua.\n",
    "\n",
    "3. **Texto de ejemplo:**\n",
    "   ```plaintext\n",
    "   Soy muy Kusikuy de aprender Quechua. Kusi es muy importante en mi vida.\n",
    "   ```\n",
    "\n",
    "4. **Resultado esperado:**\n",
    "   ```plaintext\n",
    "   soy muy kusikuy de aprender quechua. kusikuy es muy importante en mi vida.\n",
    "   ```\n",
    "\n",
    "**Ejercicio 2: Lematización en Shipibo-Konibo y Ashaninka**\n",
    "\n",
    "1. **Objetivo:** Crear un lematizador sencillo que identifique y reduzca diferentes formas morfológicas de palabras en Shipibo-Konibo y Ashaninka a su lema base.\n",
    "\n",
    "2. **Descripción:**\n",
    "   - Investiga algunas palabras comunes en Shipibo-Konibo y Ashaninka que tengan variaciones morfológicas.\n",
    "   - Escribe un script en Python que lematice estas palabras en sus formas básicas.\n",
    "   - Procesa un pequeño texto en Shipibo-Konibo y otro en Ashaninka.\n",
    "\n",
    "3. **Texto de ejemplo:**\n",
    "   - **Shipibo-Konibo:** `Metsa ikábo bakebo.`\n",
    "   - **Ashaninka:** `Jokiro anampitsi onkenero.`\n",
    "   \n",
    "4. **Resultado esperado:**\n",
    "   - **Shipibo-Konibo:** `Metsa iká bake.`\n",
    "   - **Ashaninka:** `Jokiro anampi onke.`\n",
    "   \n",
    "**Ejercicio 3: Stemming en Yine**\n",
    "\n",
    "1. **Objetivo:** Aplicar un algoritmo de stemming a un texto en Yine para reducir las palabras a sus raíces.\n",
    "\n",
    "2. **Descripción:**\n",
    "   - Crea una lista de palabras comunes en Yine con sus variantes.\n",
    "   - Implementa un algoritmo simple de stemming que elimine sufijos comunes en Yine.\n",
    "   - Aplica el algoritmo a un texto dado en Yine.\n",
    "\n",
    "3. **Texto de ejemplo:**\n",
    "   ```plaintext\n",
    "   Ichikire irako jintika iya.\n",
    "   ```\n",
    "\n",
    "4. **Resultado esperado:**\n",
    "   ```plaintext\n",
    "   Ichikir irak jintik iya.\n",
    "   ```\n",
    "\n",
    "**Ejercicio 4: Segmentación de oraciones multilingües**\n",
    "\n",
    "1. **Objetivo:** Implementar un segmentador de oraciones que funcione para textos en español, quechua, shipibo-konibo, ashaninka, y yine.\n",
    "\n",
    "2. **Descripción:**\n",
    "   - Escribe un programa en Python que pueda identificar y segmentar oraciones en los diferentes idiomas mencionados.\n",
    "   - Considera las diferentes formas en que se pueden estructurar las oraciones en estos idiomas y cómo los signos de puntuación pueden variar.\n",
    "\n",
    "3. **Texto de ejemplo:**\n",
    "   ```plaintext\n",
    "   Hablo español. Noqa rimani runasimita. Metsa iroake. Jokiro anampitsi.\n",
    "   ```\n",
    "\n",
    "4. **Resultado esperado:**\n",
    "   ```plaintext\n",
    "   ['Hablo español.', 'Noqa rimani runasimita.', 'Metsa iroake.', 'Jokiro anampitsi.']\n",
    "   ```\n",
    "\n",
    "**Ejercicio 5: Unificación de términos multilingües**\n",
    "\n",
    "1. **Objetivo:** Desarrollar un sistema de unificación de términos que trabaje con textos multilingües, particularmente en español, quechua, shipibo-konibo, ashaninka, y yine.\n",
    "\n",
    "2. **Descripción:**\n",
    "   - Escribe una función que tome un texto y reemplace palabras y expresiones que sean variantes de un mismo concepto, independientemente del idioma.\n",
    "   - Por ejemplo, unifica \"Sol\", \"Inti\" (quechua), y \"Shiro\" (shipibo-konibo) bajo un término común.\n",
    "\n",
    "3. **Texto de ejemplo:**\n",
    "   ```plaintext\n",
    "   El Inti brilla en el cielo. Shiro es el dios del sol. El Sol es poderoso.\n",
    "   ```\n",
    "\n",
    "4. **Resultado esperado:**\n",
    "   ```plaintext\n",
    "   El Sol brilla en el cielo. Sol es el dios del sol. El Sol es poderoso.\n",
    "   ```\n",
    "\n",
    "Claro, aquí tienes algunos ejercicios adicionales que complementan los anteriores y profundizan en el procesamiento de textos en español, quechua, shipibo-konibo, ashaninka, y yine.\n",
    "\n",
    "\n",
    "**Ejercicio 6: Traducción automática básica entre español y Quechua**\n",
    "\n",
    "1. **Objetivo:** Desarrollar un sistema básico de traducción automática entre español y quechua utilizando reglas simples.\n",
    "\n",
    "2. **Descripción:**\n",
    "   - Implementa un diccionario bilingüe básico que contenga palabras y frases comunes en español y quechua.\n",
    "   - Crea una función en Python que traduzca un texto en español a quechua utilizando este diccionario.\n",
    "   - Considera reglas simples de concordancia y orden de palabras.\n",
    "\n",
    "3. **Texto de ejemplo:**\n",
    "   ```plaintext\n",
    "   Mi nombre es Juan. Vivo en Cusco. Me gusta la comida.\n",
    "   ```\n",
    "\n",
    "4. **Resultado esperado:**\n",
    "   ```plaintext\n",
    "   Noqaq sutiyqa Juanmi. Cuscomanta kani. Mikhuyta munani.\n",
    "   ```\n",
    "\n",
    "**Ejercicio 7: Detección de lengua en textos multilingües**\n",
    "\n",
    "1. **Objetivo:** Implementar un algoritmo para detectar el idioma de una oración o palabra en un texto que contenga español, quechua, shipibo-konibo, ashaninka, y yine.\n",
    "\n",
    "2. **Descripción:**\n",
    "   - Crea un script que tome como entrada un texto y determine en qué idioma está cada palabra u oración.\n",
    "   - Puedes utilizar técnicas de frecuencia de palabras, características de ortografía, o un diccionario para la detección.\n",
    "\n",
    "3. **Texto de ejemplo:**\n",
    "   ```plaintext\n",
    "   Runasimipi rimayta yachani. Me gusta aprender nuevas lenguas.\n",
    "   ```\n",
    "\n",
    "4. **Resultado esperado:**\n",
    "   ```plaintext\n",
    "   [\"Runasimipi rimayta yachani.\" -> Quechua, \"Me gusta aprender nuevas lenguas.\" -> Español]\n",
    "   ```\n",
    "\n",
    "**Ejercicio 8: Generación de palabras derivadas en Ashaninka y Shipibo-Konibo**\n",
    "\n",
    "1. **Objetivo:** Crear un sistema que genere automáticamente formas derivadas de una palabra raíz en ashaninka y shipibo-konibo.\n",
    "\n",
    "2. **Descripción:**\n",
    "   - Investiga cómo se forman palabras derivadas en ashaninka y shipibo-konibo (por ejemplo, mediante la adición de sufijos).\n",
    "   - Implementa un script en Python que genere formas derivadas a partir de una raíz dada.\n",
    "\n",
    "3. **Raíces de ejemplo:**\n",
    "   - **Ashaninka:** `ankotsi` (caminar) -> Derivados esperados: `ankotsineri` (caminará), `ankotsiki` (camino).\n",
    "   - **Shipibo-Konibo:** `raoma` (comer) -> Derivados esperados: `raomake` (comiendo), `raomaoki` (comeré).\n",
    "\n",
    "**Ejercicio 9: Tokenización y análisis de frecuencia de palabras en Yine**\n",
    "\n",
    "1. **Objetivo:** Desarrollar un sistema de tokenización y análisis de frecuencia de palabras para textos en Yine.\n",
    "\n",
    "2. **Descripción:**\n",
    "   - Implementa un tokenizador que divida un texto en Yine en palabras individuales.\n",
    "   - Crea una función que cuente la frecuencia de cada palabra en el texto.\n",
    "   - Genera un listado de las palabras más frecuentes.\n",
    "\n",
    "3. **Texto de ejemplo:**\n",
    "   ```plaintext\n",
    "   Ichikire irako jintika iya. Ichikire pokanka maik. Jintika jintika ichikire.\n",
    "   ```\n",
    "\n",
    "4. **Resultado esperado:**\n",
    "   ```plaintext\n",
    "   {'ichikire': 3, 'jintika': 3, 'irako': 1, 'iya': 1, 'pokanka': 1, 'maik': 1}\n",
    "   ```\n",
    "\n",
    "**Ejercicio 10: Análisis de sentimientos en textos en español y Quechua**\n",
    "\n",
    "1. **Objetivo:** Implementar un análisis de sentimientos básico para textos en español y quechua.\n",
    "\n",
    "2. **Descripción:**\n",
    "   - Crea un diccionario de palabras con polaridad positiva y negativa tanto en español como en quechua.\n",
    "   - Escribe un script en Python que tome un texto en cualquiera de los dos idiomas y determine si el sentimiento es positivo, negativo o neutral.\n",
    "   - Considera solo palabras individuales para la polaridad.\n",
    "\n",
    "3. **Texto de ejemplo:**\n",
    "   ```plaintext\n",
    "   Amo la naturaleza y su belleza. Ñuqaq sonqoyqa kusiwan phutiy.\n",
    "   ```\n",
    "\n",
    "4. **Resultado esperado:**\n",
    "   ```plaintext\n",
    "   ['Amo la naturaleza y su belleza.' -> Positivo, 'Ñuqaq sonqoyqa kusiwan phutiy.' -> Positivo]\n",
    "   ```\n",
    "\n",
    "**Ejercicio 11: Generación de oraciones aleatorias en Ashaninka**\n",
    "\n",
    "1. **Objetivo:** Desarrollar un generador de oraciones aleatorias en ashaninka utilizando un conjunto de palabras predefinido.\n",
    "\n",
    "2. **Descripción:**\n",
    "   - Define conjuntos de sustantivos, verbos, y adjetivos en ashaninka.\n",
    "   - Implementa un programa que genere oraciones simples combinando aleatoriamente estos elementos.\n",
    "   - Asegúrate de que las oraciones sean gramaticalmente correctas dentro de las reglas de ashaninka.\n",
    "\n",
    "3. **Conjunto de palabras:**\n",
    "   - **Sustantivos:** `ona (persona)`, `mapori (jefe)`, `betiro (árbol)`\n",
    "   - **Verbos:** `onketi (ver)`, `pikoti (correr)`\n",
    "   - **Adjetivos:** `itsiri (grande)`, `inanti (rápido)`\n",
    "\n",
    "4. **Ejemplo de oración generada:**\n",
    "   ```plaintext\n",
    "   Mapori itsiri pikoti.\n",
    "   ```\n",
    "\n",
    "**Ejercicio 12: Análisis morfológico en textos en Shipibo-Konibo**\n",
    "\n",
    "1. **Objetivo:** Implementar un analizador morfológico para textos en shipibo-konibo que identifique las raíces y afijos.\n",
    "\n",
    "2. **Descripción:**\n",
    "   - Investiga la estructura morfológica de palabras en shipibo-konibo.\n",
    "   - Escribe un script en Python que descomponga una palabra en sus componentes morfológicos.\n",
    "   - Procesa un conjunto de palabras para analizar su estructura.\n",
    "\n",
    "3. **Palabras de ejemplo:**\n",
    "   ```plaintext\n",
    "   Jakonmax (bueno), Raiokon (caminando)\n",
    "   ```\n",
    "\n",
    "4. **Resultado esperado:**\n",
    "   ```plaintext\n",
    "   {'Jakonmax': {'raíz': 'Jakon', 'afijo': 'max'}, 'Raiokon': {'raíz': 'Raio', 'afijo': 'kon'}}\n",
    "   ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3906a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b9a050",
   "metadata": {},
   "source": [
    "### Distancia de edición mínima\n",
    "\n",
    "Gran parte del procesamiento del lenguaje natural se preocupa por medir cuán similares son dos cadenas. Por ejemplo, en la corrección ortográfica, el usuario escribió una cadena errónea—digamos **graffe** y queremos saber qué quiso decir el usuario. Probablemente el usuario pretendía una palabra que sea similar a **graffe**. Entre las palabras candidatas similares, la palabra **giraffe**, que difiere en solo una letra de **graffe**, parece intuitivamente más similar que, por ejemplo, **grail** o **graf**, que difieren en más letras. \n",
    "\n",
    "Otro ejemplo proviene de la **coreference**, la tarea de decidir si dos cadenas como las siguientes se refieren a la misma entidad:\n",
    "\n",
    "```plaintext\n",
    "Stanford President Marc Tessier-Lavigne\n",
    "Stanford University President Marc Tessier-Lavigne\n",
    "```\n",
    "\n",
    "Nuevamente, el hecho de que estas dos cadenas sean muy similares (diferentes solo en una palabra) parece ser una evidencia útil para decidir que podrían ser co-referentes.\n",
    "\n",
    "La **distancia de edición** nos da una forma de cuantificar ambas intuiciones sobre la similitud de cadenas. Más formalmente, la **distancia de mínima edición** entre dos cadenas se define como el número mínimo de operaciones de edición (operaciones como inserción, eliminación, sustitución) necesarias para transformar una cadena en otra.\n",
    "\n",
    "El gap entre la \"intention\" y \"execution\", por ejemplo, es de 5 (eliminar una `i`, sustituir `e` por `n`, sustituir `x` por `t`, insertar `c`, sustituir `u` por `n`). \n",
    "\n",
    "\n",
    "También podemos asignar un costo o peso particular a cada una de estas operaciones. La **distancia de Levenshtein** entre dos secuencias es el factor de ponderación más simple en el que cada una de las tres operaciones tiene un costo de 1. \n",
    "\n",
    "Asumimos que la sustitución de una letra por sí misma, por ejemplo, `t` por `t`, tiene un costo de cero. La **distancia de Levenshtein** entre \"intention\" y \"execution\" es de 5. \n",
    "\n",
    "Levenshtein también propuso una versión alternativa de su métrica en la que cada inserción o eliminación tiene un costo de 1 y no se permiten sustituciones. (Esto es equivalente a permitir la sustitución, pero dando a cada sustitución un costo de 2, ya que cualquier sustitución puede representarse mediante una inserción y una eliminación). Usando esta versión, la  entre \"intention\" y \"execution\" es de 8.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee6a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(s1, s2):\n",
    "    \"\"\"\n",
    "    Calcula la distancia de Levenshtein estándar entre dos secuencias.\n",
    "    \"\"\"\n",
    "    len_s1 = len(s1) + 1\n",
    "    len_s2 = len(s2) + 1\n",
    "\n",
    "    # Crear una matriz para almacenar los resultados parciales\n",
    "    dp = [[0] * len_s2 for _ in range(len_s1)]\n",
    "\n",
    "    # Inicializar la primera fila y columna\n",
    "    for i in range(len_s1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(len_s2):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    # Llenar la matriz\n",
    "    for i in range(1, len_s1):\n",
    "        for j in range(1, len_s2):\n",
    "            if s1[i - 1] == s2[j - 1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "\n",
    "            dp[i][j] = min(dp[i - 1][j] + 1,       # Eliminación\n",
    "                           dp[i][j - 1] + 1,       # Inserción\n",
    "                           dp[i - 1][j - 1] + cost) # Sustitución\n",
    "\n",
    "    return dp[-1][-1]\n",
    "\n",
    "def levenshtein_distance_no_substitution(s1, s2):\n",
    "    \"\"\"\n",
    "    Calcula la distancia de Levenshtein con un costo de sustitución de 2.\n",
    "    \"\"\"\n",
    "    len_s1 = len(s1) + 1\n",
    "    len_s2 = len(s2) + 1\n",
    "\n",
    "    # Crear una matriz para almacenar los resultados parciales\n",
    "    dp = [[0] * len_s2 for _ in range(len_s1)]\n",
    "\n",
    "    # Inicializar la primera fila y columna\n",
    "    for i in range(len_s1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(len_s2):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    # Llenar la matriz\n",
    "    for i in range(1, len_s1):\n",
    "        for j in range(1, len_s2):\n",
    "            if s1[i - 1] == s2[j - 1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 2  # Costo de sustitución como inserción + eliminación\n",
    "\n",
    "            dp[i][j] = min(dp[i - 1][j] + 1,       # Eliminación\n",
    "                           dp[i][j - 1] + 1,       # Inserción\n",
    "                           dp[i - 1][j - 1] + cost) # Sustitución\n",
    "\n",
    "    return dp[-1][-1]\n",
    "\n",
    "# Ejemplos de uso\n",
    "s1 = \"intention\"\n",
    "s2 = \"execution\"\n",
    "\n",
    "distancia_levenshtein = levenshtein_distance(s1, s2)\n",
    "distancia_no_substitucion = levenshtein_distance_no_substitution(s1, s2)\n",
    "\n",
    "print(f\"Distancia de Levenshtein estándar entre '{s1}' y '{s2}': {distancia_levenshtein}\")\n",
    "print(f\"Distancia de Levenshtein (sin sustituciones permitidas) entre '{s1}' y '{s2}': {distancia_no_substitucion}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74de73e",
   "metadata": {},
   "source": [
    "\n",
    "### El algoritmo de la distancia mínima\n",
    "\n",
    "¿Cómo encontramos la **distancia de edición mínima**?  Primero definamos la **distancia de edición mínima** entre dos cadenas. \n",
    "\n",
    "Dadas dos cadenas, la cadena fuente **X** de longitud **n**, y la cadena objetivo **Y** de longitud **m**, definiremos **D[i, j]** como la **distancia de edición** entre **X[1..i]** y **Y[1..j]**, es decir, los primeros **i** caracteres de **X** y los primeros **j** caracteres de **Y**. La **distancia de edición** entre **X** y **Y** es, por lo tanto, **D[n, m]**. \n",
    "\n",
    "Usaremos **programación dinámica** para calcular **D[n, m]** de abajo hacia arriba, combinando soluciones a subproblemas. En el caso base, con una subcadena fuente de longitud **i** pero una cadena objetivo vacía, pasar de **i** caracteres a 0 requiere **i** eliminaciones. Con una subcadena objetivo de longitud **j** pero un objetivo vacío, pasar de 0 caracteres a **j** caracteres requiere **j** inserciones. Habiendo calculado **D[i, j]** para **i, j** pequeños, luego calculamos valores más grandes de **D[i, j]** basados en valores más pequeños calculados previamente. \n",
    "El valor de **D[i, j]** se calcula tomando el mínimo de los tres posibles caminos a través de la matriz que llegan allí:\n",
    "\n",
    "```plaintext\n",
    "D[i, j] = min {\n",
    "    D[i - 1, j] + del-cost(source[i])\n",
    "    D[i, j - 1] + ins-cost(target[j])\n",
    "    D[i - 1, j - 1] + sub-cost(source[i], target[j])\n",
    "}\n",
    "```\n",
    "\n",
    "Mencionamos anteriormente dos versiones de la  **distancia de Levenshtein**, una en la que las sustituciones cuestan 1 y otra en la que las sustituciones cuestan 2 (es decir, son equivalentes a una inserción más una eliminación). Utilicemos aquí esa segunda versión  en la que las inserciones y eliminaciones tienen un costo de 1 (**ins-cost(·) = del-cost(·) = 1**), y las sustituciones tienen un costo de 2 (excepto la sustitución de letras idénticas, que tiene un costo de cero). \n",
    "\n",
    "Según esta versión de **Levenshtein**, el cálculo para **D[i, j]** se convierte en:\n",
    "\n",
    "```plaintext\n",
    "D[i, j] = min {\n",
    "    D[i - 1, j] + 1\n",
    "    D[i, j − 1] + 1\n",
    "    D[i - 1, j - 1] + {\n",
    "        2; si source[i] ≠ target[j]\n",
    "        0; si source[i] = target[j]\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "El algoritmo se resume de la siguiente forma y el código muestra los resultados de aplicar el algoritmo a la distancia entre \"intention\" y \"execution\" con la versión de **Levenshtein** en la ecuación anterior.\n",
    "\n",
    "```plaintext\n",
    "function MIN-EDIT-DISTANCE (source, target) returns min-distance\n",
    "n <- LENGTH (source)\n",
    "m <- LENGTH (target)\n",
    "Create a distance matrix D[n+1,m+1]\n",
    "# Initialization: the zeroth row and column is the distance from the empty string\n",
    "D[0,0] = 0\n",
    "for each row i from 1 to n do\n",
    "    D[i,0] <- D[i-1,0] + del-cost(source[i])\n",
    "for each column j from 1 to m do\n",
    "    D[0,j] <- D[0, j-1] + ins-cost(target[j])\n",
    "# Recurrence relation:\n",
    "for each row i from 1 to n do\n",
    "    for each column j from 1 to m do\n",
    "        D[i, j] ← MIN (\n",
    "            D[i−1, j] + del-cost(source[i]),\n",
    "            D[i−1, j−1] + sub-cost(source[i], target[j]),\n",
    "            D[i, j−1] + ins-cost(target[j])\n",
    "        )\n",
    "# Termination\n",
    "return D[n,m]\n",
    "```\n",
    "\n",
    "El texto anterior muestra el algoritmo de distancia de edición mínima, un ejemplo de la clase de algoritmos de programación dinámica. Los diversos costos pueden ser fijos (por ejemplo, **∀x, ins-cost(x) = 1**) o pueden ser específicos para la letra (para modelar el hecho de que algunas letras tienen más probabilidades de ser insertadas que otras). Asumimos que no hay costo por sustituir una letra por sí misma (es decir, **sub-cost(x, x) = 0**).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccb11d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_edit_distance(source, target):\n",
    "    \"\"\"\n",
    "    Calcula la distancia de edición mínima entre dos cadenas usando programación dinámica.\n",
    "    También devuelve los pasos detallados para transformar la cadena fuente en la cadena objetivo.\n",
    "    \n",
    "    Parameters:\n",
    "        source (str): La cadena fuente (X) que se quiere transformar.\n",
    "        target (str): La cadena objetivo (Y) en la que se quiere transformar la fuente.\n",
    "    \n",
    "    Returns:\n",
    "        int: La distancia mínima de edición entre la cadena fuente y la cadena objetivo.\n",
    "        list: Los pasos detallados de las operaciones realizadas.\n",
    "    \"\"\"\n",
    "    # n es la longitud de la cadena fuente\n",
    "    n = len(source)\n",
    "    # m es la longitud de la cadena objetivo\n",
    "    m = len(target)\n",
    "    \n",
    "    # Crear una matriz de (n+1) x (m+1) para almacenar las distancias\n",
    "    D = [[0 for _ in range(m + 1)] for _ in range(n + 1)]\n",
    "    # Crear una matriz para almacenar las operaciones\n",
    "    operations = [[None for _ in range(m + 1)] for _ in range(n + 1)]\n",
    "    \n",
    "    # Inicialización: la primera fila y la primera columna representan la distancia\n",
    "    # desde la cadena vacía a la cadena parcial.\n",
    "    for i in range(1, n + 1):\n",
    "        D[i][0] = i  # Cada paso cuesta 1, que representa una eliminación\n",
    "        operations[i][0] = \"delete\"\n",
    "    for j in range(1, m + 1):\n",
    "        D[0][j] = j  # Cada paso cuesta 1, que representa una inserción\n",
    "        operations[0][j] = \"insert\"\n",
    "    \n",
    "    # Relación de recurrencia: llenar la matriz utilizando las distancias mínimas\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            # Costo de eliminación\n",
    "            del_cost = D[i - 1][j] + 1\n",
    "            # Costo de inserción\n",
    "            ins_cost = D[i][j - 1] + 1\n",
    "            # Costo de sustitución (0 si son iguales, 2 si son diferentes)\n",
    "            sub_cost = D[i - 1][j - 1] + (2 if source[i - 1] != target[j - 1] else 0)\n",
    "            \n",
    "            # Determinar el camino mínimo y guardar la operación realizada\n",
    "            if sub_cost <= del_cost and sub_cost <= ins_cost:\n",
    "                D[i][j] = sub_cost\n",
    "                if source[i - 1] == target[j - 1]:\n",
    "                    operations[i][j] = \"match\"\n",
    "                else:\n",
    "                    operations[i][j] = \"substitute\"\n",
    "            elif del_cost < ins_cost:\n",
    "                D[i][j] = del_cost\n",
    "                operations[i][j] = \"delete\"\n",
    "            else:\n",
    "                D[i][j] = ins_cost\n",
    "                operations[i][j] = \"insert\"\n",
    "    \n",
    "    # Realizar el backtrace para encontrar los pasos\n",
    "    steps = []\n",
    "    i, j = n, m\n",
    "    while i > 0 or j > 0:\n",
    "        current_op = operations[i][j]\n",
    "        if current_op == \"match\" or current_op == \"substitute\":\n",
    "            steps.append(f\"{current_op} '{source[i-1]}' -> '{target[j-1]}'\")\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif current_op == \"delete\":\n",
    "            steps.append(f\"{current_op} '{source[i-1]}'\")\n",
    "            i -= 1\n",
    "        elif current_op == \"insert\":\n",
    "            steps.append(f\"{current_op} '{target[j-1]}'\")\n",
    "            j -= 1\n",
    "    \n",
    "    steps.reverse()  # Para obtener los pasos en el orden correcto\n",
    "    return D[n][m], steps\n",
    "\n",
    "# Ejemplo de uso\n",
    "source = \"intention\"\n",
    "target = \"execution\"\n",
    "distance, steps = min_edit_distance(source, target)\n",
    "\n",
    "print(f\"La mínima distancia de edición entre '{source}' y '{target}' es: {distance}\")\n",
    "print(\"Los pasos para transformar la cadena son:\")\n",
    "for step in steps:\n",
    "    print(step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16d4276",
   "metadata": {},
   "source": [
    "\n",
    "#### Algunas definiciones\n",
    "\n",
    "**Backtrace**\n",
    "\n",
    "**Backtrace** es el proceso de rastrear hacia atrás a través de una estructura de datos, generalmente una matriz de programación dinámica, para reconstruir la solución óptima de un problema. En el contexto de la distancia de edición mínima, después de llenar la matriz con los costos de las operaciones de edición, el **backtrace** comienza en la celda final (que contiene el costo total mínimo para transformar una cadena en otra) y sigue los punteros hacia atrás a través de la matriz. Esto permite reconstruir la secuencia de operaciones (inserciones, eliminaciones, sustituciones) que llevaron a esa solución óptima.\n",
    "\n",
    "**Backpointer**\n",
    "\n",
    "Un **backpointer** es un puntero o referencia almacenado en una celda de la matriz de programación dinámica que indica la celda anterior desde la que se llegó al valor actual. En otras palabras, un **backpointer** señala cuál de las posibles operaciones (inserción, eliminación, sustitución) fue la óptima para alcanzar el valor en esa celda. Durante el proceso de **backtrace**, estos **backpointers** son seguidos para reconstruir el camino de la solución óptima. Cada celda puede tener uno o más **backpointers** si varias operaciones resultaron en el mismo costo mínimo.\n",
    "\n",
    "Estas definiciones proporcionan un contexto más claro sobre cómo se utilizan estos conceptos en el algoritmo de **distancia de edición mínima** y en otros algoritmos basados en programación dinámica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082c29eb",
   "metadata": {},
   "source": [
    "### Alineación\n",
    "\n",
    "Alinear dos cadenas es una técnica útil en todo el procesamiento de voz y lenguaje. En el reconocimiento de voz, la alineación basada en la **distancia de edición mínima** se utiliza para calcular la **tasa de error de palabras**. La alineación también juega un papel crucial en la traducción automática, donde las oraciones en un **corpus paralelo** (un corpus con un texto en dos idiomas) deben ser emparejadas entre sí.\n",
    "\n",
    "Para extender el algoritmo de **distancia de edición** y producir una alineación, seguimos un proceso en dos pasos. En el primer paso, aumentamos el algoritmo de **distancia de edición mínima** para almacenar **backpointers** en cada celda. El **backpointer** de una celda apunta a la celda anterior (o celdas) de la que se derivó el valor de la celda actual. Algunas celdas pueden tener múltiples **backpointers** porque la distancia mínima podría haber venido de múltiples celdas anteriores.\n",
    "\n",
    "En el segundo paso, realizamos un **backtrace**. En un **backtrace**, comenzamos desde la última celda (en la fila y columna finales) y seguimos los punteros hacia atrás a través de la matriz de programación dinámica. Cada camino completo entre la celda final y la celda inicial representa una alineación de distancia mínima.\n",
    "\n",
    "Cuando ingresamos un valor en cada celda, marcamos de cuál de las tres celdas vecinas proviene dicho valor, utilizando hasta tres flechas. Después de que la tabla esté llena, calculamos una alineación (camino de costo mínimo) usando un **backtrace**, comenzando en la esquina inferior derecha y siguiendo las flechas hacia atrás. La secuencia de celdas en negrita representa una posible alineación de costo mínimo entre las dos cadenas, utilizando nuevamente la **distancia de Levenshtein** con un costo de 1 para inserciones o eliminaciones, y 2 para sustituciones.\n",
    "\n",
    "Aunque trabajamos nuestro ejemplo con la **distancia de Levenshtein** simple, el algoritmo mencionado anteriormente permite pesos arbitrarios en las operaciones. Para la corrección ortográfica, por ejemplo, las sustituciones son más probables entre letras que están una al lado de la otra en el teclado. El **algoritmo de Viterbi** es una extensión probabilística de la **distancia de edición mínima**. En lugar de calcular la \"distancia de edición mínima\" entre dos cadenas, **Viterbi** calcula la \"alineación de máxima probabilidad\" de una cadena con otra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c981bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_alignment(source, target, match_prob, mismatch_prob, gap_prob):\n",
    "    \"\"\"\n",
    "    Calcula la \"alineación de máxima probabilidad\" entre dos cadenas usando una variante del algoritmo de Viterbi.\n",
    "    \n",
    "    Parameters:\n",
    "        source (str): La cadena fuente que se quiere alinear.\n",
    "        target (str): La cadena objetivo a la que se quiere alinear la fuente.\n",
    "        match_prob (float): La probabilidad de una coincidencia exacta entre caracteres.\n",
    "        mismatch_prob (float): La probabilidad de una sustitución entre caracteres diferentes.\n",
    "        gap_prob (float): La probabilidad de insertar o eliminar un carácter.\n",
    "    \n",
    "    Returns:\n",
    "        float: La probabilidad máxima de alineación entre las dos cadenas.\n",
    "        list: Los pasos detallados de las operaciones realizadas en la alineación.\n",
    "    \"\"\"\n",
    "    # n es la longitud de la cadena fuente\n",
    "    n = len(source)\n",
    "    # m es la longitud de la cadena objetivo\n",
    "    m = len(target)\n",
    "    \n",
    "    # Crear una matriz de (n+1) x (m+1) para almacenar las probabilidades logarítmicas\n",
    "    V = [[-float('inf') for _ in range(m + 1)] for _ in range(n + 1)]\n",
    "    # Crear una matriz para almacenar las operaciones\n",
    "    operations = [[None for _ in range(m + 1)] for _ in range(n + 1)]\n",
    "    \n",
    "    # Inicialización: la primera fila y la primera columna representan la alineación\n",
    "    # desde la cadena vacía a la cadena parcial, penalizando con logaritmo del gap.\n",
    "    V[0][0] = 0  # Probabilidad logarítmica inicial de 0 (log(1) = 0)\n",
    "    for i in range(1, n + 1):\n",
    "        V[i][0] = V[i-1][0] + gap_prob\n",
    "        operations[i][0] = \"delete\"\n",
    "    for j in range(1, m + 1):\n",
    "        V[0][j] = V[0][j-1] + gap_prob\n",
    "        operations[0][j] = \"insert\"\n",
    "    \n",
    "    # Relación de recurrencia: llenar la matriz utilizando las probabilidades logarítmicas\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            # Cálculo de las probabilidades logarítmicas\n",
    "            match_or_mismatch = V[i-1][j-1] + (match_prob if source[i-1] == target[j-1] else mismatch_prob)\n",
    "            deletion = V[i-1][j] + gap_prob\n",
    "            insertion = V[i][j-1] + gap_prob\n",
    "            \n",
    "            # Determinar el camino de máxima probabilidad\n",
    "            if match_or_mismatch >= deletion and match_or_mismatch >= insertion:\n",
    "                V[i][j] = match_or_mismatch\n",
    "                operations[i][j] = \"match\" if source[i-1] == target[j-1] else \"substitute\"\n",
    "            elif deletion > insertion:\n",
    "                V[i][j] = deletion\n",
    "                operations[i][j] = \"delete\"\n",
    "            else:\n",
    "                V[i][j] = insertion\n",
    "                operations[i][j] = \"insert\"\n",
    "    \n",
    "    # Realizar el backtrace para encontrar los pasos\n",
    "    steps = []\n",
    "    i, j = n, m\n",
    "    while i > 0 or j > 0:\n",
    "        current_op = operations[i][j]\n",
    "        if current_op == \"match\" or current_op == \"substitute\":\n",
    "            steps.append(f\"{current_op} '{source[i-1]}' -> '{target[j-1]}'\")\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif current_op == \"delete\":\n",
    "            steps.append(f\"{current_op} '{source[i-1]}'\")\n",
    "            i -= 1\n",
    "        elif current_op == \"insert\":\n",
    "            steps.append(f\"{current_op} '{target[j-1]}'\")\n",
    "            j -= 1\n",
    "    \n",
    "    steps.reverse()  # Para obtener los pasos en el orden correcto\n",
    "    return V[n][m], steps\n",
    "\n",
    "# Ejemplo de uso\n",
    "source = \"intention\"\n",
    "target = \"execution\"\n",
    "match_prob = 0.0  # log(1) = 0 para coincidencia\n",
    "mismatch_prob = -2.0  # log(probabilidad de sustitución)\n",
    "gap_prob = -1.0  # log(probabilidad de gap)\n",
    "\n",
    "probability, steps = viterbi_alignment(source, target, match_prob, mismatch_prob, gap_prob)\n",
    "\n",
    "print(f\"La máxima probabilidad logarítmica de alineación entre '{source}' y '{target}' es: {probability}\")\n",
    "print(\"Los pasos para alinear la cadena son:\")\n",
    "for step in steps:\n",
    "    print(step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ff7b28",
   "metadata": {},
   "source": [
    "**Ejercicio 1: Distancia de edición entre \"leda\" y \"deal\"**\n",
    "\n",
    "**Pregunta:** Calcula la distancia de edición entre las palabras \"leda\" y \"deal\", usando un costo de 1 para inserciones, eliminaciones y sustituciones. Muestra tu trabajo utilizando una cuadrícula de distancia de edición.\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Crea una cuadrícula para almacenar las distancias parciales entre los prefijos de \"leda\" y \"deal\".\n",
    "2. Llena la cuadrícula calculando las distancias según los costos dados.\n",
    "3. Identifica la secuencia de operaciones (inserción, eliminación, sustitución) necesarias para transformar \"leda\" en \"deal\".\n",
    "4. Calcula la distancia mínima de edición.\n",
    "\n",
    "**Solución esperada:**\n",
    "- Deberías construir una matriz de 5x5 (ya que ambas palabras tienen 4 letras más una fila y columna para la cadena vacía).\n",
    "- Debes completar la matriz paso a paso y luego seguir la secuencia óptima para encontrar la distancia mínima.\n",
    "\n",
    "**Ejercicio 2: Comparación de palabras (\"drive\", \"brief\", \"divers\")**\n",
    "\n",
    "**Pregunta:** Determina si \"drive\" está más cerca de \"brief\" o de \"divers\" utilizando la distancia de edición. Calcula la distancia de edición entre \"drive\" y cada una de las palabras \"brief\" y \"divers\". Puedes usar cualquier versión de distancia que prefieras.\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Implementa o utiliza una función de distancia de edición para calcular la distancia entre \"drive\" y \"brief\", y entre \"drive\" y \"divers\".\n",
    "2. Usa cualquier variante de la distancia de edición (por ejemplo, costo de sustitución 1 o 2).\n",
    "3. Compara los resultados para determinar cuál de las dos palabras está más cerca de \"drive\".\n",
    "\n",
    "**Solución esperada:**\n",
    "- Debes justificar la elección de la variante de distancia de edición y mostrar cómo se calculó cada distancia.\n",
    "- Deberías poder concluir cuál de las dos palabras es más cercana a \"drive\" basándose en los resultados.\n",
    "\n",
    "**Ejercicio 3: Implementación del algoritmo de distancia de edición mínima**\n",
    "\n",
    "**Pregunta:** Implementa un algoritmo para calcular la distancia de edición mínima entre dos cadenas y utiliza los resultados que has calculado manualmente para verificar tu código.\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Implementa una función en el lenguaje de programación de tu elección para calcular la distancia de edición mínima entre dos cadenas.\n",
    "2. Usa las palabras y los resultados calculados a mano en ejercicios anteriores (como \"leda\" y \"deal\") para verificar la exactitud de tu código.\n",
    "3. Documenta cómo se valida tu implementación utilizando los ejemplos manuales.\n",
    "\n",
    "**Solución Esperada:**\n",
    "- Debes escribir un código que siga la metodología de programación dinámica para calcular la distancia de edición mínima.\n",
    "- Deberías incluir pruebas en tu código utilizando los ejemplos resueltos manualmente.\n",
    "\n",
    "\n",
    "**Ejercicio 4: Alineación y backtrace**\n",
    "\n",
    "**Pregunta:** Mejora el algoritmo de distancia de edición mínima para que también devuelva la alineación de las dos cadenas. Deberás almacenar punteros y agregar una etapa para calcular el **backtrace**.\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Modifica tu algoritmo de distancia de edición para que además de calcular la distancia, guarde los punteros necesarios para reconstruir la alineación óptima.\n",
    "2. Implementa una función de **backtrace** que recorra los punteros desde la celda final hasta la inicial para reconstruir la secuencia de operaciones.\n",
    "3. Muestra cómo tu algoritmo devuelve tanto la distancia mínima de edición como la alineación resultante entre las dos cadenas.\n",
    "\n",
    "**Solución esperada:**\n",
    "- El código debería mostrar tanto la distancia mínima de edición como una secuencia detallada de operaciones que transforman una cadena en la otra.\n",
    "- Debes verificar que la alineación producida coincide con la secuencia de operaciones mínima.\n",
    "\n",
    "\n",
    "**Ejercicio 5: Distancia de Levenshtein con costos personalizados**\n",
    "\n",
    "**Pregunta:** Modifica el algoritmo de distancia de Levenshtein para que acepte costos personalizados para cada operación (inserción, eliminación, sustitución). Luego, calcula la distancia entre \"kitten\" y \"sitting\" utilizando los siguientes costos:\n",
    "- Inserción: 1\n",
    "- Eliminación: 1\n",
    "- Sustitución: 2\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Implementa o modifica la función de distancia de Levenshtein para aceptar costos específicos para cada operación.\n",
    "2. Calcula la distancia de edición entre \"kitten\" y \"sitting\" utilizando los costos dados.\n",
    "3. Muestra los pasos realizados para obtener la distancia mínima.\n",
    "\n",
    "**Solución esperada:**\n",
    "- Debes modificar la función existente o crear una nueva que permita la personalización de costos.\n",
    "- Debes mostrar el resultado calculado y los pasos tomados.\n",
    "\n",
    "\n",
    "**Ejercicio 6: Visualización de la matriz de distancia de edición**\n",
    "\n",
    "**Pregunta:** Implementa una visualización gráfica de la matriz de distancia de edición entre dos cadenas. Usa colores o valores numéricos para mostrar la progresión de las distancias.\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Implementa un algoritmo de distancia de edición mínima.\n",
    "2. Genera la matriz de distancias entre las cadenas \"flaw\" y \"lawn\".\n",
    "3. Crea una visualización (puede ser una matriz de números o una representación gráfica) que muestre cómo se calculan las distancias en cada celda.\n",
    "\n",
    "**Solución esperada:**\n",
    "- Debes producir una visualización clara de la matriz, mostrando cómo se propagan las distancias.\n",
    "- La visualización debería ayudar a entender cómo se llega al valor final.\n",
    "\n",
    "**Ejercicio 7: Distancia de edición con transformaciones complejas**\n",
    "\n",
    "**Pregunta:** Considera un caso en el que, además de las operaciones de inserción, eliminación, y sustitución, tienes una operación adicional llamada \"transposición\", que permite intercambiar dos caracteres adyacentes con un costo de 1. Implementa este nuevo algoritmo y calcula la distancia entre \"converse\" y \"conserve\".\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Modifica el algoritmo de distancia de edición mínima para incluir la operación de transposición.\n",
    "2. Calcula la distancia de edición entre \"converse\" y \"conserve\".\n",
    "3. Muestra los pasos realizados y compara los resultados con los que obtendrías sin la operación de transposición.\n",
    "\n",
    "**Solución esperada:**\n",
    "- Debes ajustar el algoritmo para manejar transposiciones y demostrar cómo afecta al resultado.\n",
    "- Se espera que demuestren cómo la inclusión de transposiciones puede reducir la distancia de edición.\n",
    "\n",
    "**Ejercicio 8: Comparación de algoritmos de distancia de edición**\n",
    "\n",
    "**Pregunta:** Implementa y compara tres algoritmos de distancia de edición: Levenshtein estándar, Levenshtein sin sustituciones permitidas (cada sustitución cuesta 2), y el algoritmo con transposiciones. Usa estos algoritmos para calcular las distancias entre las siguientes parejas de palabras: \"abc\" y \"acb\", \"abcdef\" y \"abcfed\", \"flaw\" y \"lawn\".\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Implementa las tres variantes del algoritmo de distancia de edición.\n",
    "2. Calcula la distancia de edición para las palabras dadas usando cada variante.\n",
    "3. Compara y discute los resultados obtenidos.\n",
    "\n",
    "**Solución esperada:**\n",
    "- Debes mostrar cómo se calculan las distancias utilizando cada variante y explicar las diferencias en los resultados.\n",
    "- Debes analizar en qué casos una variante es más útil que las otras.\n",
    "\n",
    "**Ejercicio 9: Aplicación a la corrección ortográfica**\n",
    "\n",
    "**Pregunta:** Desarrolla un corrector ortográfico simple basado en la distancia de edición. Dado un diccionario de palabras y una palabra con un error tipográfico, el corrector debe sugerir la palabra correcta más cercana en el diccionario.\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Implementa una función que calcule la distancia de edición entre la palabra mal escrita y cada palabra en un diccionario.\n",
    "2. Devuelve la palabra del diccionario que tiene la menor distancia de edición con la palabra mal escrita.\n",
    "3. Prueba tu corrector ortográfico con un diccionario pequeño y algunas palabras mal escritas.\n",
    "\n",
    "**Solución esperada:**\n",
    "- Debes implementar una solución que encuentre y sugiera la palabra correcta basándose en la distancia de edición mínima.\n",
    "- Debes mostrar ejemplos de correcciones con palabras reales.\n",
    "\n",
    "**Ejercicio 10: Alineación de secuencias en Bioinformática**\n",
    "\n",
    "**Pregunta:** Aplica el algoritmo de alineación de máxima probabilidad (Viterbi) a una secuencia de ADN. Usa un puntaje de coincidencia de +1, un costo de desajuste de -1, y un costo de gap de -2 para alinear las secuencias \"ACGTGCA\" y \"ACGTCGA\".\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Implementa el algoritmo de alineación de máxima probabilidad con los puntajes y costos dados.\n",
    "2. Calcula la alineación óptima entre las dos secuencias de ADN.\n",
    "3. Muestra el alineamiento resultante y explica cómo se calcula la máxima probabilidad logarítmica.\n",
    "\n",
    "**Solución esperada:**\n",
    "- Debes implementar el algoritmo, mostrar la alineación resultante y discutir cómo se llega a la solución óptima en términos de probabilidad logarítmica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe0a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Tus respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9c5e25",
   "metadata": {},
   "source": [
    "**Respuesta a algunos ejercicios:**\n",
    "\n",
    "Implementa una visualización gráfica de la matriz de distancia de edición entre dos cadenas. Usa colores o valores numéricos para mostrar la progresión de las distancias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fbe17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def min_edit_distance_matrix(source, target):\n",
    "    n = len(source)\n",
    "    m = len(target)\n",
    "    \n",
    "    # Crear una matriz (n+1) x (m+1)\n",
    "    D = np.zeros((n + 1, m + 1), dtype=int)\n",
    "    \n",
    "    # Inicialización de la primera fila y columna\n",
    "    for i in range(1, n + 1):\n",
    "        D[i][0] = i\n",
    "    for j in range(1, m + 1):\n",
    "        D[0][j] = j\n",
    "    \n",
    "    # Llenar la matriz\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            if source[i - 1] == target[j - 1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "            D[i][j] = min(D[i - 1][j] + 1,       # Eliminación\n",
    "                          D[i][j - 1] + 1,       # Inserción\n",
    "                          D[i - 1][j - 1] + cost) # Sustitución\n",
    "    \n",
    "    return D\n",
    "\n",
    "# Visualización de la matriz\n",
    "def visualize_edit_distance_matrix(source, target):\n",
    "    D = min_edit_distance_matrix(source, target)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(D, annot=True, fmt=\"d\", cmap=\"YlGnBu\", cbar=False)\n",
    "    plt.title(f\"Matriz de Distancia de Edición: '{source}' vs '{target}'\")\n",
    "    plt.xlabel(\"Target\")\n",
    "    plt.ylabel(\"Source\")\n",
    "    plt.xticks(np.arange(len(target) + 1), [''] + list(target))\n",
    "    plt.yticks(np.arange(len(source) + 1), [''] + list(source))\n",
    "    plt.show()\n",
    "\n",
    "# Ejemplo de uso\n",
    "source = \"flaw\"\n",
    "target = \"lawn\"\n",
    "visualize_edit_distance_matrix(source, target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db79228",
   "metadata": {},
   "source": [
    "Implementa y compara tres algoritmos de distancia de edición: Levenshtein estándar, Levenshtein sin sustituciones permitidas (cada sustitución cuesta 2), y el algoritmo con transposiciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cd63d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(s1, s2):\n",
    "    n = len(s1)\n",
    "    m = len(s2)\n",
    "    D = np.zeros((n + 1, m + 1), dtype=int)\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        D[i][0] = i\n",
    "    for j in range(1, m + 1):\n",
    "        D[0][j] = j\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            cost = 0 if s1[i - 1] == s2[j - 1] else 1\n",
    "            D[i][j] = min(D[i - 1][j] + 1, D[i][j - 1] + 1, D[i - 1][j - 1] + cost)\n",
    "    \n",
    "    return D[n][m]\n",
    "\n",
    "def levenshtein_no_substitution(s1, s2):\n",
    "    n = len(s1)\n",
    "    m = len(s2)\n",
    "    D = np.zeros((n + 1, m + 1), dtype=int)\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        D[i][0] = i\n",
    "    for j in range(1, m + 1):\n",
    "        D[0][j] = j\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            cost = 2 if s1[i - 1] != s2[j - 1] else 0\n",
    "            D[i][j] = min(D[i - 1][j] + 1, D[i][j - 1] + 1, D[i - 1][j - 1] + cost)\n",
    "    \n",
    "    return D[n][m]\n",
    "\n",
    "def damerau_levenshtein(s1, s2):\n",
    "    n = len(s1)\n",
    "    m = len(s2)\n",
    "    D = np.zeros((n + 1, m + 1), dtype=int)\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        D[i][0] = i\n",
    "    for j in range(1, m + 1):\n",
    "        D[0][j] = j\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            cost = 0 if s1[i - 1] == s2[j - 1] else 1\n",
    "            D[i][j] = min(D[i - 1][j] + 1, D[i][j - 1] + 1, D[i - 1][j - 1] + cost)\n",
    "\n",
    "            if i > 1 and j > 1 and s1[i - 1] == s2[j - 2] and s1[i - 2] == s2[j - 1]:\n",
    "                D[i][j] = min(D[i][j], D[i - 2][j - 2] + 1)  # Transposición\n",
    "    \n",
    "    return D[n][m]\n",
    "\n",
    "# Comparación de las tres variantes\n",
    "def compare_algorithms(word_pairs):\n",
    "    results = {}\n",
    "    for s1, s2 in word_pairs:\n",
    "        results[(s1, s2)] = {\n",
    "            \"Levenshtein estándar\": levenshtein_distance(s1, s2),\n",
    "            \"Levenshtein sin sustitución\": levenshtein_no_substitution(s1, s2),\n",
    "            \"Damerau-Levenshtein (con transposición)\": damerau_levenshtein(s1, s2)\n",
    "        }\n",
    "    return results\n",
    "\n",
    "# Palabras de ejemplo\n",
    "word_pairs = [\n",
    "    (\"abc\", \"acb\"),\n",
    "    (\"abcdef\", \"abcfed\"),\n",
    "    (\"flaw\", \"lawn\")\n",
    "]\n",
    "\n",
    "# Ejecutar comparación\n",
    "results = compare_algorithms(word_pairs)\n",
    "\n",
    "# Mostrar resultados\n",
    "for pair, distances in results.items():\n",
    "    print(f\"Comparación entre '{pair[0]}' y '{pair[1]}':\")\n",
    "    for alg, dist in distances.items():\n",
    "        print(f\"  {alg}: {dist}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
